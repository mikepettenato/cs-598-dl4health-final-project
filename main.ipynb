{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import datetime\n",
    "import gensim\n",
    "import numpy as np\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import torch, stanza\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import threading\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T00:35:01.824854Z",
     "end_time": "2023-04-08T00:35:02.331708Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Processing\n",
    "\n",
    "This section can have stuff related to data prep.\n",
    "\n",
    "\n",
    "Should the MSPC Dataset be a part of this section? - Adam"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def read_file(file_name):\n",
    "    # Note: Unable to use pd.read_csv... the function complained about an issue with the formatting of the tsv file\n",
    "    # train = pd.read_csv('data/msr_paraphrase_train.txt', sep='\\t', encoding='latin1')\n",
    "    # train\n",
    "\n",
    "    # opting to read file in and split columns manually to create a pandas dataframe\n",
    "    list = []\n",
    "    with open(file_name, encoding=\"utf8\") as f:\n",
    "        lines = f.readlines()\n",
    "        for i, line in enumerate(lines):\n",
    "            fields = line.split('\\t')\n",
    "            list.append(fields)\n",
    "\n",
    "    df = pd.DataFrame(list[1:], columns=['Quality', 'ID1', 'ID2', 'String1', 'String2'])\n",
    "    return df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T00:35:01.868489Z",
     "end_time": "2023-04-08T00:35:02.351344Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Definition\n",
    "\n",
    "![Model Overview](./images/overview.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Input Layer\n",
    "\n",
    "In the input layer is made up of a Stanford Parser to provide a syntactic tree so that the model can extract significant words (mainly, subject, predicate, object) in the input corpus. Word2Vec is then used to map the words into vectors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-12 12:04:43 INFO: Loading these models for language: en (English):\n",
      "===========================\n",
      "| Processor    | Package  |\n",
      "---------------------------\n",
      "| tokenize     | combined |\n",
      "| pos          | combined |\n",
      "| constituency | wsj      |\n",
      "===========================\n",
      "\n",
      "2023-04-12 12:04:43 INFO: Using device: cpu\n",
      "2023-04-12 12:04:43 INFO: Loading: tokenize\n",
      "2023-04-12 12:04:43 INFO: Loading: pos\n",
      "2023-04-12 12:04:44 INFO: Loading: constituency\n",
      "2023-04-12 12:04:44 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "# set 'download_method = None' to not download the resources over and over\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,pos,constituency', download_method=None, use_gpu=False)\n",
    "\n",
    "def trunk_construction(str, parent_label = None):\n",
    "    doc = nlp(str)\n",
    "    tree = doc.sentences[0].constituency\n",
    "\n",
    "    words = construct_sentence(tree, parent_label)\n",
    "    return ' '.join(words)\n",
    "\n",
    "def construct_sentence(tree, parent_label = None, leave_pos=False):\n",
    "\n",
    "    sentences = []\n",
    "    if 'NN' in tree.label:\n",
    "        if parent_label == 'NP':\n",
    "            # sentences.append(tree)\n",
    "            sentences = sentences + tree.leaf_labels()\n",
    "    if 'VB' in tree.label:\n",
    "        if parent_label == 'VP':\n",
    "            #sentences.append(tree)\n",
    "            sentences = sentences + tree.leaf_labels()\n",
    "    for child in tree.children:\n",
    "        sentences = sentences + construct_sentence(child, tree.label)\n",
    "\n",
    "    return sentences\n",
    "\n",
    "def find_branches(tree, label, not_in_label=None, ancestors=[]):\n",
    "    branches = []\n",
    "    # print(\"-------------\")\n",
    "    # print(ancestors)\n",
    "    # print(f\"{tree.label} == {label}\")\n",
    "    if tree.label == label and not_in_label not in ancestors:\n",
    "        # print(f\"adding {tree}\")\n",
    "        branches.append(tree)\n",
    "    for child in tree.children:\n",
    "        branches = branches + find_branches(child, label, not_in_label, ancestors + [tree.label])\n",
    "\n",
    "    return branches\n",
    "\n",
    "#\n",
    "# # According to the paper the subject is the first NN child of NP\n",
    "def find_subject(noun_phrase_for_subject):\n",
    "    subject = []\n",
    "    for child in noun_phrase_for_subject.children:\n",
    "        if 'NN' in child.label:\n",
    "            subject = subject + child.leaf_labels()\n",
    "\n",
    "    #print(f\"subject = {subject}\")\n",
    "    #if len(subject) > 0:\n",
    "    #    return ' '.join(subject)\n",
    "    return subject\n",
    "\n",
    "    return None\n",
    "\n",
    "def find_predicate(verb_phrase_for_predicate):\n",
    "    predicate = []\n",
    "    for child in verb_phrase_for_predicate.children:\n",
    "        if child.label.startswith('VB'):\n",
    "            predicate = predicate + child.leaf_labels()\n",
    "\n",
    "    if len(predicate) > 0:\n",
    "        return ' '.join(predicate)\n",
    "\n",
    "    return None\n",
    "\n",
    "def find_object(verb_phase_for_object, parent='VP'):\n",
    "    objects = []\n",
    "    for child in verb_phase_for_object.children:\n",
    "        if child.label == 'VP':\n",
    "            continue\n",
    "        if 'NN' in child.label and parent in ['NP', 'PP', 'ADJP']:\n",
    "            #objects = objects + child.leaf_labels()\n",
    "            new_objects = child.leaf_labels()\n",
    "            for new_object in new_objects:\n",
    "                if new_object not in objects:\n",
    "                    objects.append(new_object)\n",
    "        else:\n",
    "            new_objects = find_object(child, child.label)\n",
    "            #if new_objects not in objects and new_objects is not None:\n",
    "            for new_object in new_objects:\n",
    "                if new_object not in objects:\n",
    "                    objects.append(new_object)\n",
    "                #objects = objects + new_objects\n",
    "\n",
    "    return objects\n",
    "    # if len(objects) > 0:\n",
    "    #     #return ' '.join(objects)\n",
    "    #     return objects\n",
    "    # else:\n",
    "    #     return None\n",
    "\n",
    "def find_spo(tree):\n",
    "    noun_phrases_for_subject = find_branches(tree, label='NP', not_in_label='VP', ancestors=[])\n",
    "    subject_list = []\n",
    "    for noun_phrase_for_subject in noun_phrases_for_subject:\n",
    "        subject = find_subject(noun_phrase_for_subject)\n",
    "        #if subject is not None:\n",
    "        #   subject_list.append(subject)\n",
    "        subject_list = subject_list + subject\n",
    "\n",
    "    verb_phrases = find_branches(tree, label='VP')\n",
    "    predicate_list = []\n",
    "    object_list = []\n",
    "    for verb_phrase in verb_phrases:\n",
    "        predicate = find_predicate(verb_phrase)\n",
    "        if predicate is not None:\n",
    "            predicate_list.append(predicate)\n",
    "        object = find_object(verb_phrase)\n",
    "        object_list = object_list + object\n",
    "        #if object is not None:\n",
    "        #    object_list.append(object)\n",
    "\n",
    "    # dedupe list\n",
    "    subject_list = list(dict.fromkeys(subject_list))\n",
    "    predicate_list = list(dict.fromkeys(predicate_list))\n",
    "    object_list = list(dict.fromkeys(object_list))\n",
    "\n",
    "    return subject_list, predicate_list, object_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T00:35:01.890215Z",
     "end_time": "2023-04-08T00:35:03.008883Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    " def test_parser(str, valid_subject, valid_predicate, valid_object):\n",
    "\n",
    "    #new_sentence = trunk_construction(str)\n",
    "    #print(new_sentence)\n",
    "    #assert new_sentence == valid_sentence\n",
    "\n",
    "    doc = nlp(str)\n",
    "    tree = doc.sentences[0].constituency\n",
    "\n",
    "    subject_list, predicate_list, object_list = find_spo(tree)\n",
    "    print(f\"Subject = {' '.join(subject_list)}\")\n",
    "    print(f\"Predicate = {' '.join(predicate_list)}\")\n",
    "    print(f\"Object = {' '.join(object_list)}\")\n",
    "\n",
    "    print(f\"{subject_list} = {valid_subject}\")\n",
    "    print(f\"{predicate_list} = {valid_predicate}\")\n",
    "    print(f\"{object_list} = {valid_object}\")\n",
    "    assert subject_list == valid_subject\n",
    "    assert predicate_list == valid_predicate\n",
    "    assert object_list == valid_object\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T00:35:03.013569Z",
     "end_time": "2023-04-08T00:35:03.015960Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Parser Test Cases\n",
    "Test the parser using some of the training data sentences as input and asserting the output sentence matches the algorithm defined in the paper."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject = \n",
      "Predicate = have do is designing\n",
      "Object = amount work set architectures\n",
      "[] = []\n",
      "['have', 'do', 'is', 'designing'] = ['have', 'do', 'is', 'designing']\n",
      "['amount', 'work', 'set', 'architectures'] = ['amount', 'work', 'set', 'architectures']\n",
      "Subject = instruction set\n",
      "Predicate = have got do said\n",
      "Object = amount work\n",
      "['instruction', 'set'] = ['instruction', 'set']\n",
      "['have', 'got', 'do', 'said'] = ['have', 'got', 'do', 'said']\n",
      "['amount', 'work'] = ['amount', 'work']\n",
      "Subject = forces\n",
      "Predicate = launch\n",
      "Object = attacks\n",
      "['forces'] = ['forces']\n",
      "['launch'] = ['launch']\n",
      "['attacks'] = ['attacks']\n",
      "Subject = tire\n",
      "Predicate = was replaced\n",
      "Object = driver\n",
      "['tire'] = ['tire']\n",
      "['was', 'replaced'] = ['was', 'replaced']\n",
      "['driver'] = ['driver']\n",
      "Subject = Amrozi\n",
      "Predicate = accused called distorting\n",
      "Object = brother witness evidence\n",
      "['Amrozi'] = ['Amrozi']\n",
      "['accused', 'called', 'distorting'] = ['accused', 'called', 'distorting']\n",
      "['brother', 'witness', 'evidence'] = ['brother', 'witness', 'evidence']\n",
      "Subject = Amrozi\n",
      "Predicate = Referring accused distorting\n",
      "Object = witness brother evidence\n",
      "['Amrozi'] = ['Amrozi']\n",
      "['Referring', 'accused', 'distorting'] = ['Referring', 'accused', 'distorting']\n",
      "['witness', 'brother', 'evidence'] = ['witness', 'brother', 'evidence']\n",
      "Subject = Shares Genentech company products market\n",
      "Predicate = rose\n",
      "Object = percent\n",
      "['Shares', 'Genentech', 'company', 'products', 'market'] = ['Shares', 'Genentech', 'company', 'products', 'market']\n",
      "['rose'] = ['rose']\n",
      "['percent'] = ['percent']\n",
      "Subject = Shares Xoma\n",
      "Predicate = fell were\n",
      "Object = percent trade shares Genentech company products market\n",
      "['Shares', 'Xoma'] = ['Shares', 'Xoma']\n",
      "['fell', 'were'] = ['fell', 'were']\n",
      "['percent', 'trade', 'shares', 'Genentech', 'company', 'products', 'market'] = ['percent', 'trade', 'shares', 'Genentech', 'company', 'products', 'market']\n",
      "Subject = Gyorgy Heizler head disaster unit\n",
      "Predicate = said was carrying\n",
      "Object = coach passengers\n",
      "['Gyorgy', 'Heizler', 'head', 'disaster', 'unit'] = ['Gyorgy', 'Heizler', 'head', 'disaster', 'unit']\n",
      "['said', 'was', 'carrying'] = ['said', 'was', 'carrying']\n",
      "['coach', 'passengers'] = ['coach', 'passengers']\n",
      "Subject = head disaster unit Gyorgy Heizler\n",
      "Predicate = said had failed heed\n",
      "Object = coach driver stop lights\n",
      "['head', 'disaster', 'unit', 'Gyorgy', 'Heizler'] = ['head', 'disaster', 'unit', 'Gyorgy', 'Heizler']\n",
      "['said', 'had', 'failed', 'heed'] = ['said', 'had', 'failed', 'heed']\n",
      "['coach', 'driver', 'stop', 'lights'] = ['coach', 'driver', 'stop', 'lights']\n",
      "Subject = Sheena Young Child network\n",
      "Predicate = hoped lead\n",
      "Object = guidelines service infertility sufferers\n",
      "['Sheena', 'Young', 'Child', 'network'] = ['Sheena', 'Young', 'Child', 'network']\n",
      "['hoped', 'lead'] = ['hoped', 'lead']\n",
      "['guidelines', 'service', 'infertility', 'sufferers'] = ['guidelines', 'service', 'infertility', 'sufferers']\n",
      "Subject = Sheena Young Child network\n",
      "Predicate = said lead\n",
      "Object = guidelines service infertility sufferers\n",
      "['Sheena', 'Young', 'Child', 'network'] = ['Sheena', 'Young', 'Child', 'network']\n",
      "['said', 'lead'] = ['said', 'lead']\n",
      "['guidelines', 'service', 'infertility', 'sufferers'] = ['guidelines', 'service', 'infertility', 'sufferers']\n"
     ]
    }
   ],
   "source": [
    "test_parser(\"\"\"\"We have an incredible amount of work to do, but it is not in [designing new] instruction set architectures.\"\"\", [], ['have', 'do', 'is', 'designing'], ['amount', 'work', 'set', 'architectures'])\n",
    "test_parser(\"\"\"We have got an incredible amount of work to do, but it ain't in the instruction set,\" he said.\"\"\",  ['instruction', 'set'], ['have', 'got', 'do', 'said'], ['amount', 'work'])\n",
    "test_parser('Syrian forces launch new attacks', ['forces'], ['launch'], ['attacks'])\n",
    "test_parser(\"\"\"the flat tire was replaced by the driver\"\"\", ['tire'], ['was', 'replaced'], ['driver'])\n",
    "test_parser(\"\"\"Amrozi accused his brother, whom he called \"the witness\", of deliberately distorting his evidence.\"\"\",\n",
    "            ['Amrozi'], ['accused', 'called', 'distorting'], ['brother',  'witness', 'evidence'])\n",
    "test_parser(\"\"\"Referring to him as only \"the witness\", Amrozi accused his brother of deliberately distorting his evidence.\"\"\",\n",
    "         ['Amrozi'], ['Referring', 'accused', 'distorting'], ['witness', 'brother', 'evidence'])\n",
    "test_parser(\"\"\"Shares of Genentech, a much larger company with several products on the market, rose more than 2 percent\"\"\",\n",
    "            ['Shares', 'Genentech', 'company', 'products', 'market'], ['rose'], ['percent'])\n",
    "\n",
    "test_parser(\"\"\"Shares of Xoma fell 16 percent in early trade, while shares of Genentech, a much larger company with several products on the market, were up 2 percent.\"\"\", ['Shares', 'Xoma'], ['fell', 'were'], ['percent', 'trade', 'shares', 'Genentech', 'company', 'products', 'market'])\n",
    "\n",
    "test_parser(\"\"\"Gyorgy Heizler, head of the local disaster unit, said the coach was carrying 38 passengers.\"\"\",\n",
    "              ['Gyorgy', 'Heizler', 'head', 'disaster', 'unit'], ['said', 'was', 'carrying'], ['coach', 'passengers'])\n",
    "test_parser(\"\"\"The head of the local disaster unit, Gyorgy Heizler, said the coach driver had failed to heed red stop lights.\"\"\",\n",
    "            ['head', 'disaster', 'unit', 'Gyorgy', 'Heizler'], ['said', 'had', 'failed', 'heed'], ['coach', 'driver', 'stop', 'lights'])\n",
    "# test_parser(\"\"\"His wife said he was \"100 percent behind George Bush\" and looked forward to using his years of training in the war.\"\"\",\n",
    "#             \"wife said was percent George Bush looked using years training war\")\n",
    "test_parser(\"\"\"Sheena Young of Child, the national infertility support network, hoped the guidelines would lead to a more \"fair and equitable\" service for infertility sufferers\"\"\", ['Sheena', 'Young', 'Child', 'network'], ['hoped', 'lead'], ['guidelines', 'service', 'infertility', 'sufferers'])\n",
    "test_parser(\"\"\"Sheena Young, for Child, the national infertility support network, said the proposed guidelines should lead to a more \"fair and equitable\" service for infertility sufferers.\"\"\", ['Sheena', 'Young', 'Child', 'network'], ['said', 'lead'], ['guidelines', 'service', 'infertility', 'sufferers'])\n",
    "#\n",
    "# test_parser(\"\"\"Among CNN viewers, 29 percent said they were Republicans and 36 percent called themselves conservatives.\"\"\",\n",
    "#             \"CNN viewers percent said were Republicans percent called conservatives\")\n",
    "# test_parser(\"\"\"Out of Fox viewers, 41 percent describe themselves as Republicans, 24 percent as Democrats and 30 percent as Independents\"\"\",\n",
    "#             \"Fox viewers percent describe Republicans percent Democrats percent Independents\")\n",
    "\n",
    "# Note: stanza parser has a problem with the below sentence.  It is unable to parse it correctly\n",
    "# test_parser(\"\"\"Sheena Young, for Child, the national infertility support network, said the proposed guidelines should lead to a more \"fair and equitable\" service for infertility sufferers.\"\"\", \"\")\n",
    "# test_parser(\"\"\"Among Fox viewers, 41 percent describe themselves as Republicans, 24 percent as Democrats and 30 percent as Independents\"\"\", \"Fox viewers percent describe Republicans percent Democrats percent Independents\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T00:35:03.023262Z",
     "end_time": "2023-04-08T00:35:08.918548Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Concurrency Parsing\n",
    "Added support for concurrent parsing.  This can help in the performance of the preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class SentenceProcessingThread(threading.Thread):\n",
    "    def __init__(self, sentences, output_list, begin, end):\n",
    "        super(SentenceProcessingThread, self).__init__()\n",
    "        self.sentences = sentences\n",
    "        self.nlp = stanza.Pipeline(lang='en', processors='tokenize,pos,constituency', download_method=None, use_gpu=True)\n",
    "        self.output_list = output_list\n",
    "        self.begin = begin\n",
    "        self.end = end\n",
    "\n",
    "    def trunk_construction(self, str, parent_label = None):\n",
    "        doc = self.nlp(str)\n",
    "        tree = doc.sentences[0].constituency\n",
    "\n",
    "        #words = construct_sentence(tree, parent_label)\n",
    "        #return ' '.join(words)\n",
    "\n",
    "        subjects, predicates, objects = find_spo(tree)\n",
    "\n",
    "        return f\"{' '.join(subjects)},{' '.join(predicates)},{' '.join(objects)}\"\n",
    "\n",
    "    def run(self):\n",
    "        print(f\"going to process {self.begin} to {self.end}\")\n",
    "        for i, sentence in enumerate(self.sentences):\n",
    "            new_sentence = self.trunk_construction(sentence)\n",
    "            self.output_list[self.begin + i] = new_sentence\n",
    "\n",
    "def process_sentences_concurrently(sentences, output, p=2):\n",
    "    total = len(sentences)\n",
    "    interval = int(total / p)\n",
    "    threads = []\n",
    "    for i in range(p):\n",
    "        s = i*interval\n",
    "        if i == p-1:\n",
    "            e = total\n",
    "        else:\n",
    "            e = (i+1) * interval\n",
    "        sentences_slice = sentences[s:e]\n",
    "        sentence_thread = SentenceProcessingThread(sentences_slice, output, s, e)\n",
    "        sentence_thread.start()\n",
    "        threads.append(sentence_thread)\n",
    "\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "def preprocess_corpus(input_file='data/msr_paraphrase_train.txt', output_file='data/msr_paraphrase_train_stanza.txt', N=None):\n",
    "    print(output_file)\n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"{output_file} already exists\")\n",
    "        return\n",
    "\n",
    "    starttime = datetime.datetime.now()\n",
    "    df = read_file(input_file)\n",
    "\n",
    "    if N is None:\n",
    "        N = len(df.String1)\n",
    "\n",
    "    output1 = [None] * N\n",
    "    output2 = [None] * N\n",
    "\n",
    "    # we can process with more threads if we only have CPU\n",
    "    p = 8\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        # if cuda is available we don't need that many threads\n",
    "        # and if the number of threads is set too large using cuda\n",
    "        # we can get out of memory exceptions\n",
    "        p = 2\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    process_sentences_concurrently(df.String1[:N], output1, p)\n",
    "\n",
    "    # try and be careful with gpu memory\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    process_sentences_concurrently(df.String2[:N], output2, p)\n",
    "\n",
    "    endtime = datetime.datetime.now()\n",
    "\n",
    "    print(f\"time to process {N*2} sentences is {endtime - starttime}\")\n",
    "\n",
    "    stanza_df = df[:N]\n",
    "\n",
    "    processed_string1 = pd.Series(output1)\n",
    "    # processed_string1.apply(gensim.utils.simple_preprocess)\n",
    "    processed_string2 = pd.Series(output2)\n",
    "    #processed_string2.apply(gensim.utils.simple_preprocess)\n",
    "\n",
    "    stanza_df.String1 = processed_string1\n",
    "    stanza_df.String2 = processed_string2\n",
    "\n",
    "    # write the file out.  This can help in the future\n",
    "    print(f\"about to write out {output_file}\")\n",
    "    stanza_df.to_csv(output_file, sep=\"\\t\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T00:35:08.905455Z",
     "end_time": "2023-04-08T00:35:08.941546Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sentence Preprocessing\n",
    "pass the input sentences from the training dataset through the stanford/stanza parser, extracting the relevant parts of speech and then tokenize the processed sentences using the gensim.utils.simple_preprocess utility"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# start_time = datetime.datetime.now()\n",
    "#\n",
    "# processed_string1 = df[:500].String1.apply(trunk_construction)\n",
    "# processed_string2 = df[:500].String2.apply(trunk_construction)\n",
    "#\n",
    "# end_time = datetime.datetime.now()\n",
    "#\n",
    "# print (f\"Processing 200 sentences with stanza library took {end_time - start_time}\")\n",
    "#\n",
    "# start_time = datetime.datetime.now()\n",
    "#\n",
    "# processed_string1 = processed_string1.apply(gensim.utils.simple_preprocess)\n",
    "# processed_string2 = processed_string2.apply(gensim.utils.simple_preprocess)\n",
    "#\n",
    "# end_time = datetime.datetime.now()\n",
    "#\n",
    "# print (f\"Processing 200 sentences with gensim.utils.simple_preprocess took {end_time - start_time}\")\n",
    "# print(f\"Number of sentences processed in the String1 column: len(processed_string1\")\n",
    "# print(f\"Number of sentences processed in the String2 column: len(processed_string2\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T00:35:08.907470Z",
     "end_time": "2023-04-08T00:35:08.942412Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Word2Vec Embeddings\n",
    "Take the preprocessed and tokenized sentences and use Word2Vec to get the word embeddings.  Take each word embedding in a sentence and find the mean which will represent the embedding for the sentence."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# from gensim.models import Word2Vec\n",
    "#\n",
    "# corpus = pd.concat([processed_string1, processed_string2], ignore_index=True)\n",
    "#\n",
    "# #model = Word2Vec(sentences=corpus, vector_size=(len(processed_string1) + len(processed_string2)), min_count=2)\n",
    "# # set vector size to reduce computational complexity\n",
    "# model = Word2Vec(sentences=corpus, min_count=1, window=2, vector_size=50)\n",
    "# #model.build_vocab(sentences=corpus)\n",
    "# #model.train(corpus, total_examples=model.corpus_count, epochs=5)\n",
    "#\n",
    "# print(model)\n",
    "# print(model.wv.key_to_index)\n",
    "#\n",
    "# model.wv.get_vector('president')\n",
    "#\n",
    "# # for index, word in enumerate(model.wv.index_to_key):\n",
    "# #     if index == 120:\n",
    "# #         break\n",
    "# #     print(f\"word #{index}/{len(model.wv.index_to_key)} is {word}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T00:35:08.908218Z",
     "end_time": "2023-04-08T00:35:08.942594Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Function is broken out for testing purposes\n",
    "def generate_word2vec_model(corpus):\n",
    "    # Creating the Word2Vec model\n",
    "    model = Word2Vec(sentences=corpus, min_count=1, window=2, vector_size=50)\n",
    "\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T00:35:08.908525Z",
     "end_time": "2023-04-08T00:35:08.942658Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Function is broken out for testing purposes\n",
    "def sentence_embeddings(w2v_model, sentence, size):\n",
    "    np_embedding = np.zeros(size)\n",
    "    for i, word in enumerate(sentence):\n",
    "        #print(word)\n",
    "        np_embedding[i] = w2v_model.wv.get_vector(word)\n",
    "\n",
    "    return np_embedding\n",
    "    # list = []\n",
    "    # for word in sentence:\n",
    "    #     list.append(w2v_model.wv.get_vector(word))\n",
    "    #\n",
    "    # word_matrix = np.row_stack(list)\n",
    "    # #return np.mean(word_matrix, axis=0)\n",
    "    # return word_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T00:35:08.910846Z",
     "end_time": "2023-04-08T00:35:08.942887Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def test_word2vec():\n",
    "\n",
    "    df = read_file('data/msr_paraphrase_train.txt')\n",
    "\n",
    "    sentences1 = df.String1[:5].apply(gensim.utils.simple_preprocess)\n",
    "    sentences2 = df.String2[:5].apply(gensim.utils.simple_preprocess)\n",
    "\n",
    "    corpus = pd.concat([sentences1, sentences2], ignore_index=True)\n",
    "\n",
    "    max_sentence_len = corpus.apply(len).max()\n",
    "\n",
    "    model = generate_word2vec_model(corpus)\n",
    "\n",
    "    embedding = sentence_embeddings(model, corpus[0], (max_sentence_len, 50))\n",
    "    assert embedding.shape == (max_sentence_len, 50)\n",
    "\n",
    "    # Not sure if this will always generate the same embedding\n",
    "    # test_embedding = np.array([-0.00113049, -0.00124808,  0.00252251,  0.00058141,  0.00187964,  0.00379025,\n",
    "    #           -0.00012356,  0.00347055, -0.00241507,  0.00545258, -0.00574078, -0.00489824,\n",
    "    #           -0.00224492,  0.00744946,  0.00350835, -0.00139295, -0.00081134,  0.00655962,\n",
    "    #           0.00244374, -0.00447209, -0.00124291, -0.00092616,  0.0021044,  -0.00092541,\n",
    "    #           0.00284307,  0.00367638,  0.00364716,  0.00519976, -0.00088121,  0.00109841,\n",
    "    #           -0.00219322, -0.00372483,  0.00078702, -0.00612309, -0.00312131,  0.00088071,\n",
    "    #           0.00503909, -0.0009484,  -0.00068209, -0.0004782,   0.00367015,  0.00314679,\n",
    "    #           -0.00302592,  0.00346377,  0.00151145, -0.00076442, -0.0012528,  -0.00087095,\n",
    "    #           -0.00075365,  0.00468711])\n",
    "    #\n",
    "    #\n",
    "    # # not sure if this will always be equal based on comment on test_embedding variable\n",
    "    # assert np.allclose(embedding, test_embedding)\n",
    "\n",
    "test_word2vec()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T00:35:08.911696Z",
     "end_time": "2023-04-08T00:35:09.477774Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def init_word2vec(train_input_file, test_input_file):\n",
    "\n",
    "    file_parts = os.path.splitext(train_input_file)\n",
    "    train_output_file = f\"{file_parts[0]}_stanza{file_parts[1]}\"\n",
    "    print(\"About to preprocess data\")\n",
    "    preprocess_corpus(input_file=train_input_file, output_file=train_output_file)\n",
    "    print(\"Done preprocessing data\")\n",
    "\n",
    "    file_parts = os.path.splitext(test_input_file)\n",
    "    test_output_file = f\"{file_parts[0]}_stanza{file_parts[1]}\"\n",
    "    print(\"About to preprocess data\")\n",
    "    preprocess_corpus(input_file=test_input_file, output_file=test_output_file)\n",
    "    print(\"Done preprocessing data\")\n",
    "\n",
    "\n",
    "    train_df = pd.read_csv(train_output_file, sep=\"\\t\")\n",
    "    test_df = pd.read_csv(test_output_file, sep=\"\\t\")\n",
    "\n",
    "    # train_df = read_file(train)\n",
    "    # test_df = read_file(test)\n",
    "\n",
    "    train_sentences1 = train_df.String1.apply(gensim.utils.simple_preprocess)\n",
    "    train_sentences2 = train_df.String2.apply(gensim.utils.simple_preprocess)\n",
    "    test_sentences1 = test_df.String1.apply(gensim.utils.simple_preprocess)\n",
    "    test_sentences2 = test_df.String2.apply(gensim.utils.simple_preprocess)\n",
    "\n",
    "    corpus = pd.concat([train_sentences1, train_sentences2, test_sentences1, test_sentences2], ignore_index=True)\n",
    "    max_sentence_len = corpus.apply(len).max()\n",
    "\n",
    "    word2vec = generate_word2vec_model(corpus)\n",
    "\n",
    "\n",
    "    return word2vec, max_sentence_len\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def corpus_embeddings(model, corpus, max_sentence_len):\n",
    "    corpus_size = len(corpus)\n",
    "    embeddings_list = []\n",
    "    embedding_matrix = np.zeros((corpus_size, max_sentence_len, 50))\n",
    "    for i, sentence in enumerate(corpus):\n",
    "        embeddings = sentence_embeddings(model, sentence, size=(max_sentence_len, 50))\n",
    "        embedding_matrix[i] = embeddings\n",
    "        embeddings_list.append(embeddings)\n",
    "\n",
    "    return embedding_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T00:35:08.972122Z",
     "end_time": "2023-04-08T00:35:09.479438Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Dataset for the MSPC dataset\n",
    "class MSPCDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        tsv_file (string): path to the tsv file with sentences to compare and associate quality score\n",
    "        num_records (int): number of records to load.  Defaults to None which is all\n",
    "    \"\"\"\n",
    "    def __init__(self, tsv_file, w2v_model, max_sentence_length, num_records=None):\n",
    "\n",
    "        self.max_sentence_len = max_sentence_length\n",
    "        self.w2v_model = w2v_model\n",
    "\n",
    "        file_parts = os.path.splitext(tsv_file)\n",
    "        output_file = f\"{file_parts[0]}_stanza{file_parts[1]}\"\n",
    "        print(\"About to preprocess data\")\n",
    "        preprocess_corpus(input_file=tsv_file, output_file=output_file)\n",
    "        print(\"Done preprocessing data\")\n",
    "\n",
    "\n",
    "        #df = read_file('data/msr_paraphrase_train.txt')\n",
    "        df = pd.read_csv(output_file, sep=\"\\t\")\n",
    "\n",
    "        if num_records is not None:\n",
    "            processed_string1 = df[:num_records].String1\n",
    "            processed_string2 = df[:num_records].String2\n",
    "            self.quality = df[:num_records].Quality\n",
    "        else:\n",
    "            processed_string1 = df.String1\n",
    "            processed_string2 = df.String2\n",
    "            self.quality = df.Quality\n",
    "\n",
    "        processed_string1 = processed_string1.apply(gensim.utils.simple_preprocess)\n",
    "        processed_string2 = processed_string2.apply(gensim.utils.simple_preprocess)\n",
    "\n",
    "        #corpus = pd.concat([processed_string1, processed_string2], ignore_index=True)\n",
    "\n",
    "\n",
    "        #self.max_sentence_len = corpus.apply(len).max()\n",
    "\n",
    "        #w2v_model = generate_word2vec_model(corpus)\n",
    "\n",
    "        sentence_embeddings1 = corpus_embeddings(self.w2v_model, processed_string1, max_sentence_len=self.max_sentence_len)\n",
    "        sentence_embeddings2 = corpus_embeddings(self.w2v_model, processed_string2, max_sentence_len=self.max_sentence_len)\n",
    "\n",
    "        #self.w2v_model = w2v_model\n",
    "        self.sentences_embeddings1 = sentence_embeddings1\n",
    "        self.sentences_embeddings2 = sentence_embeddings2\n",
    "\n",
    "        # print (f\"Processing 200 sentences with gensim.utils.simple_preprocess took {end_time - start_time}\")\n",
    "        print(f\"Number of sentences processed in the String1 column: {len(processed_string1)}\")\n",
    "        print(f\"Number of sentences processed in the String2 column: {len(processed_string2)}\")\n",
    "        #print(self.sentences_embeddings1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences_embeddings1)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        #return torch.FloatTensor(np.stack((self.sentences_embeddings1[i], self.sentences_embeddings2[i]))), self.quality[i]\n",
    "        return torch.FloatTensor(self.sentences_embeddings1[i]), torch.FloatTensor(self.sentences_embeddings2[i]), self.quality[i]\n",
    "\n",
    "    def get_max_sentence_length(self):\n",
    "        return self.max_sentence_len"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T00:35:08.981724Z",
     "end_time": "2023-04-08T00:35:09.479637Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to preprocess data\n",
      "data/msr_paraphrase_train_stanza.txt\n",
      "data/msr_paraphrase_train_stanza.txt already exists\n",
      "Done preprocessing data\n",
      "About to preprocess data\n",
      "data/msr_paraphrase_test_stanza.txt\n",
      "data/msr_paraphrase_test_stanza.txt already exists\n",
      "Done preprocessing data\n",
      "About to preprocess data\n",
      "data/msr_paraphrase_train_stanza.txt\n",
      "data/msr_paraphrase_train_stanza.txt already exists\n",
      "Done preprocessing data\n",
      "Number of sentences processed in the String1 column: 10\n",
      "Number of sentences processed in the String2 column: 10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[83], line 15\u001B[0m\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m x1\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m2\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m50\u001B[39m\n\u001B[0;32m     11\u001B[0m     \u001B[38;5;66;03m# for set in dataset:\u001B[39;00m\n\u001B[0;32m     12\u001B[0m     \u001B[38;5;66;03m#     print(len(set[0]), len(set[1]))\u001B[39;00m\n\u001B[0;32m     13\u001B[0m     \u001B[38;5;66;03m# print(len(dataset[0][0]))\u001B[39;00m\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;66;03m# print(dataset[0])\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m \u001B[43mtest_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[83], line 6\u001B[0m, in \u001B[0;36mtest_dataset\u001B[1;34m()\u001B[0m\n\u001B[0;32m      3\u001B[0m dataset \u001B[38;5;241m=\u001B[39m MSPCDataset(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata/msr_paraphrase_train.txt\u001B[39m\u001B[38;5;124m'\u001B[39m, word2vec, max_sentence_length, \u001B[38;5;241m10\u001B[39m)\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(dataset) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m10\u001B[39m\n\u001B[1;32m----> 6\u001B[0m x1, y1 \u001B[38;5;241m=\u001B[39m dataset[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m x1\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m x1\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m max_sentence_length\n",
      "\u001B[1;31mValueError\u001B[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "def test_dataset():\n",
    "    word2vec, max_sentence_length = init_word2vec('data/msr_paraphrase_train.txt', 'data/msr_paraphrase_test.txt')\n",
    "    dataset = MSPCDataset('data/msr_paraphrase_train.txt', word2vec, max_sentence_length, 10)\n",
    "    assert len(dataset) == 10\n",
    "\n",
    "    x1, y1 = dataset[0]\n",
    "    assert x1.shape[0] == 2\n",
    "    assert x1.shape[1] == max_sentence_length\n",
    "    assert x1.shape[2] == 50\n",
    "\n",
    "    # for set in dataset:\n",
    "    #     print(len(set[0]), len(set[1]))\n",
    "    # print(len(dataset[0][0]))\n",
    "    # print(dataset[0])\n",
    "test_dataset()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T14:32:14.561411Z",
     "end_time": "2023-04-07T14:32:14.897963Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataloaders\n",
    "Create training and test dataloaders"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to preprocess data\n",
      "data/msr_paraphrase_train_stanza.txt\n",
      "data/msr_paraphrase_train_stanza.txt already exists\n",
      "Done preprocessing data\n",
      "About to preprocess data\n",
      "data/msr_paraphrase_test_stanza.txt\n",
      "data/msr_paraphrase_test_stanza.txt already exists\n",
      "Done preprocessing data\n",
      "About to preprocess data\n",
      "data/msr_paraphrase_train_stanza.txt\n",
      "data/msr_paraphrase_train_stanza.txt already exists\n",
      "Done preprocessing data\n",
      "Number of sentences processed in the String1 column: 4076\n",
      "Number of sentences processed in the String2 column: 4076\n",
      "About to preprocess data\n",
      "data/msr_paraphrase_test_stanza.txt\n",
      "data/msr_paraphrase_test_stanza.txt already exists\n",
      "Done preprocessing data\n",
      "Number of sentences processed in the String1 column: 1725\n",
      "Number of sentences processed in the String2 column: 1725\n"
     ]
    }
   ],
   "source": [
    "word2vec, max_sentence_length = init_word2vec('data/msr_paraphrase_train.txt', 'data/msr_paraphrase_test.txt')\n",
    "train_dataset = MSPCDataset('data/msr_paraphrase_train.txt', word2vec, max_sentence_length)\n",
    "test_dataset = MSPCDataset('data/msr_paraphrase_test.txt', word2vec, max_sentence_length)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def conv_output_volume(W, F, S, P):\n",
    "\n",
    "    \"\"\"\n",
    "    TODO: Given the input volume size $W$, the kernel/filter size $F$,\n",
    "    the stride $S$, and the amount of zero padding $P$ used on the border,\n",
    "    calculate the output volume size.\n",
    "    Note the output should a integer.\n",
    "    \"\"\"\n",
    "\n",
    "    # your code here\n",
    "    #https://cs231n.github.io/convolutional-networks/\n",
    "\n",
    "    return int((W-F+2*P)/S+1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T14:32:15.557166Z",
     "end_time": "2023-04-07T14:32:15.560063Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "print(conv_output_volume(50, 3, 1, 1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T14:32:18.231576Z",
     "end_time": "2023-04-07T14:32:18.377984Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pooling Layers\n",
    "\n",
    "The original paper used a dynamic k-max pooling method in their model. The _k_ value is determine by equation (1).\n",
    "\n",
    "\\begin{equation*} k=\\max \\left({k_{top},\\left \\lceil{ \\frac {L-l}{L} \\left |{ s }\\right | }\\right \\rceil }\\right)\\end{equation*}\n",
    "\n",
    "__Dynamic K-Max Pooling Implementation:__"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# #https://gist.github.com/anna-hope/7a2b2e66c3645aa8e4f94dbf06aed8dc\n",
    "# \"\"\"\n",
    "# TODO: Remove hardcoded values and max it dynamic.\n",
    "# \"\"\"\n",
    "# class DynamicKMaxPooling(nn.Module):\n",
    "#     def __init__(self, k_init, conv_layers, layer):\n",
    "#         super().__init__()\n",
    "#         # \"L is the total  number  of  convolutional  layers\n",
    "#         # in  the  network;\n",
    "#         # ktop is the fixed pooling parameter for the\n",
    "#         # topmost  convolutional  layer\"\n",
    "#         self.k_init = k_init\n",
    "#         self.conv_layers = conv_layers\n",
    "#         self.layer = layer\n",
    "#\n",
    "#     def forward(self, X):\n",
    "#         s = 50\n",
    "#         dyn_k = ((self.conv_layers - self.layer) / self.conv_layers) * 3\n",
    "#         k_max = int(round(max(self.k_init, np.ceil(dyn_k))))\n",
    "#         print(k_max)\n",
    "#         out = F.max_pool1d(X, kernel_size=k_max)\n",
    "#         return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T15:50:59.023740Z",
     "end_time": "2023-04-07T15:50:59.325715Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sentence Similarity Convolution Network (SSCN)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pooling Layers\n",
    "\n",
    "The original paper used a dynamic k-max pooling method in their model. The _k_ value is determine by equation (1).\n",
    "\n",
    "\\begin{equation*} k=\\max \\left({k_{top},\\left \\lceil{ \\frac {L-l}{L} \\left |{ s }\\right | }\\right \\rceil }\\right)\\end{equation*}\n",
    "\n",
    "__Dynamic K-Max Pooling Implementation:__"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "#https://gist.github.com/anna-hope/7a2b2e66c3645aa8e4f94dbf06aed8dc\n",
    "\"\"\"\n",
    "TODO: Remove hardcoded values and max it dynamic.\n",
    "\"\"\"\n",
    "class DynamicKMaxPooling(nn.Module):\n",
    "    def __init__(self, k_init, conv_layers):\n",
    "        super().__init__()\n",
    "        # \"L is the total  number  of  convolutional  layers\n",
    "        # in  the  network;\n",
    "        # ktop is the fixed pooling parameter for the\n",
    "        # topmost  convolutional  layer\"\n",
    "        self.k_init = k_init\n",
    "        self.conv_layers = conv_layers\n",
    "\n",
    "    def pool(self, X, l):\n",
    "        # s is sequence length\n",
    "        # l is current layer in network\n",
    "        s = X.shape[2]\n",
    "        dyn_k = ((self.conv_layers - l) / self.conv_layers) * s\n",
    "        k_max = int(round(max(self.k_init, np.ceil(dyn_k))))\n",
    "        return F.max_pool1d(X, kernel_size=k_max)\n",
    "\n",
    "    def forward(self, X):\n",
    "        for layer_i in range(self.conv_layers,0,-1):\n",
    "            X = self.pool(X, layer_i)\n",
    "\n",
    "        return X"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T00:35:09.384185Z",
     "end_time": "2023-04-08T00:35:09.528064Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testing Dynamic K-Max Pooling Layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "NUM_OF_SAMPLES = 20\n",
    "SAMPLE_SIZE = 2\n",
    "OUTPUT_SIZE = 15\n",
    "\n",
    "test_embedding = torch.rand((NUM_OF_SAMPLES, SAMPLE_SIZE, OUTPUT_SIZE))\n",
    "dyn_k_layer = DynamicKMaxPooling(3, SAMPLE_SIZE)\n",
    "\n",
    "# Call forward with convolution layer index [2,1]\n",
    "out = dyn_k_layer(test_embedding)\n",
    "\n",
    "assert out.shape[2] == 1\n",
    "assert out.shape[1] == SAMPLE_SIZE\n",
    "assert out.shape[0] == NUM_OF_SAMPLES"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T00:35:09.384376Z",
     "end_time": "2023-04-08T00:35:09.528155Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sentence Similarity\n",
    "\n",
    " \\begin{align*} Man(\\vec V_{x}, \\vec V_{y})=&\\left |{ x_{1}-y_{1} }\\right |\\! +\\! \\left |{ x_{2}-y_{2} }\\right | \\!+ \\!\\ldots \\!+ \\!\\left |{ x_{n}-y_{n} }\\right |\n",
    " \\\\ score=&e^{-Man(\\vec V_{x}, \\vec V_{y})},\\quad score\\in [{0,1}] \\end{align*}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "* X: Pooled output of SSCN model of shape (sample_size, -1)\n",
    "* For the purpose of this experiment sample_size = 2\n",
    "\"\"\"\n",
    "def manhattan_similarity_score(X):\n",
    "    sample_count, _, M = X.shape\n",
    "    Vx = X[:,0].reshape((sample_count,M))\n",
    "    Vy = X[:,1].reshape((sample_count,M))\n",
    "    mdist = torch.sum(torch.abs(Vx-Vy),dim=1).view(sample_count,-1)\n",
    "    score = torch.exp(-1*mdist)\n",
    "    return score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T00:35:09.385728Z",
     "end_time": "2023-04-08T00:35:09.528218Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "class SentenceSimilarityCNN(nn.Module):\n",
    "    def __init__(self, max_sentence_size, stride=1, kernel_size=3, padding=1):\n",
    "        super(SentenceSimilarityCNN, self).__init__()\n",
    "        self.max_sentence_size = max_sentence_size\n",
    "        self.stride = stride\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=2, out_channels=2, kernel_size=self.kernel_size, padding=self.padding)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "        # [64, 2, 19, 50] -> [B, num_sent, max_sent_len, embedding_size]\n",
    "        out1 = ((19 - self.kernel_size + 2*self.padding)/self.stride) + 1\n",
    "        out2 = ((50 - self.kernel_size + 2*self.padding)/self.stride) + 1\n",
    "\n",
    "        print(f\"out1: {out1} & out2: {out2}\")\n",
    "\n",
    "        # TODO: change this to k-max pooling\n",
    "        self.pooling = nn.MaxPool2d(kernel_size=3)\n",
    "\n",
    "        pool_out1 = (out1 - self.kernel_size) + 1\n",
    "\n",
    "        pool_out2 = (out2 - self.kernel_size) + 1\n",
    "\n",
    "        print(f\"pool_out1: {pool_out1} & pool_out2: {pool_out2}\")\n",
    "\n",
    "\n",
    "        output_volume = conv_output_volume(50, self.kernel_size, self.padding, self.stride)\n",
    "        print(f\"output_volume = {output_volume}\")\n",
    "        self.fc = nn.Linear(in_features=192, out_features=100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(f\"shape before convolution {x.shape}\")\n",
    "        x = self.conv1(x)\n",
    "        #print(f\"shape after convolution {x.shape}\")\n",
    "\n",
    "        x = self.activation(x)\n",
    "        x = self.pooling(x)\n",
    "        #print(f\"shape after pooling {x.shape}\")\n",
    "\n",
    "        # permute_x = torch.permute(x, (1, 0, 2, 3))\n",
    "        # x1 = permute_x[0]\n",
    "        # x2 = permute_x[1]\n",
    "\n",
    "        x = x.view(x.size()[0], -1)\n",
    "\n",
    "        x = self.fc(x)\n",
    "        x = x.reshape(x.shape[0], 2, 50)\n",
    "        x = torch.permute(x, (1, 0, 2))\n",
    "        man_dist = torch.sum(torch.abs(x[0] - x[1]), axis=1)\n",
    "        # sentence1_mean = torch.mean(x1, axis=1)\n",
    "        # sentence2_mean = torch.mean(x2, axis=1)\n",
    "        # man_dist = torch.sum(torch.abs(sentence1_mean - sentence2_mean), axis=1)\n",
    "        # print(man_dist.shape)\n",
    "\n",
    "        return torch.exp(-man_dist)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out1: 19.0 & out2: 50.0\n",
      "pool_out1: 17.0 & pool_out2: 48.0\n",
      "output_volume = 50\n",
      "Epoch 0: curr_epoch_loss=0.36798620223999023\n",
      "Epoch 1: curr_epoch_loss=0.343498557806015\n",
      "Epoch 2: curr_epoch_loss=0.3940209448337555\n",
      "Epoch 3: curr_epoch_loss=0.42498064041137695\n",
      "Epoch 4: curr_epoch_loss=0.35715600848197937\n",
      "Epoch 5: curr_epoch_loss=0.37894731760025024\n",
      "Epoch 6: curr_epoch_loss=0.4048773944377899\n",
      "Epoch 7: curr_epoch_loss=0.37443989515304565\n",
      "Epoch 8: curr_epoch_loss=0.5081177353858948\n",
      "Epoch 9: curr_epoch_loss=0.3915632963180542\n",
      "Epoch 10: curr_epoch_loss=0.332899272441864\n",
      "Epoch 11: curr_epoch_loss=0.33313697576522827\n",
      "Epoch 12: curr_epoch_loss=0.2960118055343628\n",
      "Epoch 13: curr_epoch_loss=0.3621475100517273\n",
      "Epoch 14: curr_epoch_loss=0.3528667688369751\n",
      "Epoch 15: curr_epoch_loss=0.41477689146995544\n",
      "Epoch 16: curr_epoch_loss=0.39315104484558105\n",
      "Epoch 17: curr_epoch_loss=0.43017303943634033\n",
      "Epoch 18: curr_epoch_loss=0.44279441237449646\n",
      "Epoch 19: curr_epoch_loss=0.542695164680481\n",
      "Epoch 20: curr_epoch_loss=0.6455597281455994\n",
      "Epoch 21: curr_epoch_loss=0.6621339917182922\n",
      "Epoch 22: curr_epoch_loss=0.674031138420105\n",
      "Epoch 23: curr_epoch_loss=0.580166220664978\n",
      "Epoch 24: curr_epoch_loss=0.5113239288330078\n",
      "Epoch 25: curr_epoch_loss=0.40448710322380066\n",
      "Epoch 26: curr_epoch_loss=0.545637845993042\n",
      "Epoch 27: curr_epoch_loss=0.34069421887397766\n",
      "Epoch 28: curr_epoch_loss=0.4233773350715637\n",
      "Epoch 29: curr_epoch_loss=0.3978760838508606\n",
      "Epoch 30: curr_epoch_loss=0.4248250722885132\n",
      "Epoch 31: curr_epoch_loss=0.3147527575492859\n",
      "Epoch 32: curr_epoch_loss=0.37450727820396423\n",
      "Epoch 33: curr_epoch_loss=0.5081808567047119\n",
      "Epoch 34: curr_epoch_loss=0.4954121708869934\n",
      "Epoch 35: curr_epoch_loss=0.5481774210929871\n",
      "Epoch 36: curr_epoch_loss=0.577039361000061\n",
      "Epoch 37: curr_epoch_loss=0.6389510631561279\n",
      "Epoch 38: curr_epoch_loss=0.42715489864349365\n",
      "Epoch 39: curr_epoch_loss=0.48900604248046875\n",
      "Epoch 40: curr_epoch_loss=0.49545377492904663\n",
      "Epoch 41: curr_epoch_loss=0.6309349536895752\n",
      "Epoch 42: curr_epoch_loss=0.3279382288455963\n",
      "Epoch 43: curr_epoch_loss=0.5197000503540039\n",
      "Epoch 44: curr_epoch_loss=0.4651864469051361\n",
      "Epoch 45: curr_epoch_loss=0.6129800081253052\n",
      "Epoch 46: curr_epoch_loss=0.5478631258010864\n",
      "Epoch 47: curr_epoch_loss=0.3901103734970093\n",
      "Epoch 48: curr_epoch_loss=0.44701701402664185\n",
      "Epoch 49: curr_epoch_loss=0.4924110174179077\n",
      "Epoch 50: curr_epoch_loss=0.4701201915740967\n",
      "Epoch 51: curr_epoch_loss=0.400740385055542\n",
      "Epoch 52: curr_epoch_loss=0.43894004821777344\n",
      "Epoch 53: curr_epoch_loss=0.5264921188354492\n",
      "Epoch 54: curr_epoch_loss=0.5816365480422974\n",
      "Epoch 55: curr_epoch_loss=0.4841005802154541\n",
      "Epoch 56: curr_epoch_loss=0.580223798751831\n",
      "Epoch 57: curr_epoch_loss=0.675121545791626\n",
      "Epoch 58: curr_epoch_loss=0.6746222376823425\n",
      "Epoch 59: curr_epoch_loss=0.6440621614456177\n",
      "Epoch 60: curr_epoch_loss=0.6370078325271606\n",
      "Epoch 61: curr_epoch_loss=0.45448702573776245\n",
      "Epoch 62: curr_epoch_loss=0.6138795614242554\n",
      "Epoch 63: curr_epoch_loss=0.6003561019897461\n",
      "Epoch 64: curr_epoch_loss=0.5961642265319824\n",
      "Epoch 65: curr_epoch_loss=0.5730247497558594\n",
      "Epoch 66: curr_epoch_loss=0.38385528326034546\n",
      "Epoch 67: curr_epoch_loss=0.37952643632888794\n",
      "Epoch 68: curr_epoch_loss=0.4600103199481964\n",
      "Epoch 69: curr_epoch_loss=0.4905887842178345\n",
      "Epoch 70: curr_epoch_loss=0.37396323680877686\n",
      "Epoch 71: curr_epoch_loss=0.3361801207065582\n",
      "Epoch 72: curr_epoch_loss=0.5295519828796387\n",
      "Epoch 73: curr_epoch_loss=0.6285078525543213\n",
      "Epoch 74: curr_epoch_loss=0.46313607692718506\n",
      "Epoch 75: curr_epoch_loss=0.36161839962005615\n",
      "Epoch 76: curr_epoch_loss=0.35436367988586426\n",
      "Epoch 77: curr_epoch_loss=0.335621178150177\n",
      "Epoch 78: curr_epoch_loss=0.4709774851799011\n",
      "Epoch 79: curr_epoch_loss=0.54426109790802\n",
      "Epoch 80: curr_epoch_loss=0.5278911590576172\n",
      "Epoch 81: curr_epoch_loss=0.41261357069015503\n",
      "Epoch 82: curr_epoch_loss=0.3397114872932434\n",
      "Epoch 83: curr_epoch_loss=0.4212006628513336\n",
      "Epoch 84: curr_epoch_loss=0.5858597755432129\n",
      "Epoch 85: curr_epoch_loss=0.5459409952163696\n",
      "Epoch 86: curr_epoch_loss=0.6419971585273743\n",
      "Epoch 87: curr_epoch_loss=0.674238920211792\n",
      "Epoch 88: curr_epoch_loss=0.5928500890731812\n",
      "Epoch 89: curr_epoch_loss=0.4836193919181824\n",
      "Epoch 90: curr_epoch_loss=0.3982812166213989\n",
      "Epoch 91: curr_epoch_loss=0.3975829482078552\n",
      "Epoch 92: curr_epoch_loss=0.4179946184158325\n",
      "Epoch 93: curr_epoch_loss=0.5273895263671875\n",
      "Epoch 94: curr_epoch_loss=0.4092499911785126\n",
      "Epoch 95: curr_epoch_loss=0.399213969707489\n",
      "Epoch 96: curr_epoch_loss=0.35075700283050537\n",
      "Epoch 97: curr_epoch_loss=0.5081636905670166\n",
      "Epoch 98: curr_epoch_loss=0.5563479661941528\n",
      "Epoch 99: curr_epoch_loss=0.5226680040359497\n",
      "Epoch 100: curr_epoch_loss=0.5077261924743652\n",
      "Epoch 101: curr_epoch_loss=0.43009892106056213\n",
      "Epoch 102: curr_epoch_loss=0.5108218789100647\n",
      "Epoch 103: curr_epoch_loss=0.5479590892791748\n",
      "Epoch 104: curr_epoch_loss=0.5426376461982727\n",
      "Epoch 105: curr_epoch_loss=0.410051554441452\n",
      "Epoch 106: curr_epoch_loss=0.5575960278511047\n",
      "Epoch 107: curr_epoch_loss=0.673269510269165\n",
      "Epoch 108: curr_epoch_loss=0.6255072951316833\n",
      "Epoch 109: curr_epoch_loss=0.6725594401359558\n",
      "Epoch 110: curr_epoch_loss=0.5389085412025452\n",
      "Epoch 111: curr_epoch_loss=0.673747181892395\n",
      "Epoch 112: curr_epoch_loss=0.5766121745109558\n",
      "Epoch 113: curr_epoch_loss=0.4607592821121216\n",
      "Epoch 114: curr_epoch_loss=0.43419691920280457\n",
      "Epoch 115: curr_epoch_loss=0.5085452198982239\n",
      "Epoch 116: curr_epoch_loss=0.4248610734939575\n",
      "Epoch 117: curr_epoch_loss=0.4013296365737915\n",
      "Epoch 118: curr_epoch_loss=0.4598078429698944\n",
      "Epoch 119: curr_epoch_loss=0.525897741317749\n",
      "Epoch 120: curr_epoch_loss=0.3542412519454956\n",
      "Epoch 121: curr_epoch_loss=0.42002415657043457\n",
      "Epoch 122: curr_epoch_loss=0.5847674608230591\n",
      "Epoch 123: curr_epoch_loss=0.4566088914871216\n",
      "Epoch 124: curr_epoch_loss=0.5773934721946716\n",
      "Epoch 125: curr_epoch_loss=0.5190395712852478\n",
      "Epoch 126: curr_epoch_loss=0.5581282377243042\n",
      "Epoch 127: curr_epoch_loss=0.5775755643844604\n",
      "Epoch 128: curr_epoch_loss=0.4380776286125183\n",
      "Epoch 129: curr_epoch_loss=0.43721693754196167\n",
      "Epoch 130: curr_epoch_loss=0.3639480471611023\n",
      "Epoch 131: curr_epoch_loss=0.3418926000595093\n",
      "Epoch 132: curr_epoch_loss=0.4331228733062744\n",
      "Epoch 133: curr_epoch_loss=0.32944270968437195\n",
      "Epoch 134: curr_epoch_loss=0.3421763479709625\n",
      "Epoch 135: curr_epoch_loss=0.5208618640899658\n",
      "Epoch 136: curr_epoch_loss=0.6708105802536011\n",
      "Epoch 137: curr_epoch_loss=0.41302597522735596\n",
      "Epoch 138: curr_epoch_loss=0.32212963700294495\n",
      "Epoch 139: curr_epoch_loss=0.31570953130722046\n",
      "Epoch 140: curr_epoch_loss=0.38802018761634827\n",
      "Epoch 141: curr_epoch_loss=0.343294233083725\n",
      "Epoch 142: curr_epoch_loss=0.33756962418556213\n",
      "Epoch 143: curr_epoch_loss=0.3891213536262512\n",
      "Epoch 144: curr_epoch_loss=0.47787559032440186\n",
      "Epoch 145: curr_epoch_loss=0.48949506878852844\n",
      "Epoch 146: curr_epoch_loss=0.5458681583404541\n",
      "Epoch 147: curr_epoch_loss=0.38281261920928955\n",
      "Epoch 148: curr_epoch_loss=0.32891321182250977\n",
      "Epoch 149: curr_epoch_loss=0.2971394658088684\n",
      "Epoch 150: curr_epoch_loss=0.5583119988441467\n",
      "Epoch 151: curr_epoch_loss=0.44972723722457886\n",
      "Epoch 152: curr_epoch_loss=0.44271352887153625\n",
      "Epoch 153: curr_epoch_loss=0.5081549882888794\n",
      "Epoch 154: curr_epoch_loss=0.46881788969039917\n",
      "Epoch 155: curr_epoch_loss=0.3064568042755127\n",
      "Epoch 156: curr_epoch_loss=0.39616847038269043\n",
      "Epoch 157: curr_epoch_loss=0.32157641649246216\n",
      "Epoch 158: curr_epoch_loss=0.4567807912826538\n",
      "Epoch 159: curr_epoch_loss=0.32195693254470825\n",
      "Epoch 160: curr_epoch_loss=0.3415401577949524\n",
      "Epoch 161: curr_epoch_loss=0.42859506607055664\n",
      "Epoch 162: curr_epoch_loss=0.4902353286743164\n",
      "Epoch 163: curr_epoch_loss=0.4843860864639282\n",
      "Epoch 164: curr_epoch_loss=0.34143608808517456\n",
      "Epoch 165: curr_epoch_loss=0.3667108416557312\n",
      "Epoch 166: curr_epoch_loss=0.3823130130767822\n",
      "Epoch 167: curr_epoch_loss=0.3612622618675232\n",
      "Epoch 168: curr_epoch_loss=0.393420934677124\n",
      "Epoch 169: curr_epoch_loss=0.38873839378356934\n",
      "Epoch 170: curr_epoch_loss=0.34588423371315\n",
      "Epoch 171: curr_epoch_loss=0.342104434967041\n",
      "Epoch 172: curr_epoch_loss=0.3544245660305023\n",
      "Epoch 173: curr_epoch_loss=0.408927857875824\n",
      "Epoch 174: curr_epoch_loss=0.4694283604621887\n",
      "Epoch 175: curr_epoch_loss=0.3534146845340729\n",
      "Epoch 176: curr_epoch_loss=0.340850293636322\n",
      "Epoch 177: curr_epoch_loss=0.330520361661911\n",
      "Epoch 178: curr_epoch_loss=0.3603215217590332\n",
      "Epoch 179: curr_epoch_loss=0.36834365129470825\n",
      "Epoch 180: curr_epoch_loss=0.32910293340682983\n",
      "Epoch 181: curr_epoch_loss=0.32570409774780273\n",
      "Epoch 182: curr_epoch_loss=0.330439031124115\n",
      "Epoch 183: curr_epoch_loss=0.3230067491531372\n",
      "Epoch 184: curr_epoch_loss=0.37642496824264526\n",
      "Epoch 185: curr_epoch_loss=0.33296436071395874\n",
      "Epoch 186: curr_epoch_loss=0.31814250349998474\n",
      "Epoch 187: curr_epoch_loss=0.46591025590896606\n",
      "Epoch 188: curr_epoch_loss=0.4948031008243561\n",
      "Epoch 189: curr_epoch_loss=0.6461219787597656\n",
      "Epoch 190: curr_epoch_loss=0.6294511556625366\n",
      "Epoch 191: curr_epoch_loss=0.6338433623313904\n",
      "Epoch 192: curr_epoch_loss=0.4291039705276489\n",
      "Epoch 193: curr_epoch_loss=0.3095267713069916\n",
      "Epoch 194: curr_epoch_loss=0.3247867226600647\n",
      "Epoch 195: curr_epoch_loss=0.30669352412223816\n",
      "Epoch 196: curr_epoch_loss=0.30642616748809814\n",
      "Epoch 197: curr_epoch_loss=0.31816235184669495\n",
      "Epoch 198: curr_epoch_loss=0.3334183990955353\n",
      "Epoch 199: curr_epoch_loss=0.30981627106666565\n",
      "Epoch 200: curr_epoch_loss=0.3325527012348175\n",
      "Epoch 201: curr_epoch_loss=0.3343401551246643\n",
      "Epoch 202: curr_epoch_loss=0.33226272463798523\n",
      "Epoch 203: curr_epoch_loss=0.3273860812187195\n",
      "Epoch 204: curr_epoch_loss=0.3384922742843628\n",
      "Epoch 205: curr_epoch_loss=0.314741313457489\n",
      "Epoch 206: curr_epoch_loss=0.31635206937789917\n",
      "Epoch 207: curr_epoch_loss=0.32816004753112793\n",
      "Epoch 208: curr_epoch_loss=0.3396533727645874\n",
      "Epoch 209: curr_epoch_loss=0.34906938672065735\n",
      "Epoch 210: curr_epoch_loss=0.3042851686477661\n",
      "Epoch 211: curr_epoch_loss=0.3285996913909912\n",
      "Epoch 212: curr_epoch_loss=0.3027016818523407\n",
      "Epoch 213: curr_epoch_loss=0.3173285126686096\n",
      "Epoch 214: curr_epoch_loss=0.31215381622314453\n",
      "Epoch 215: curr_epoch_loss=0.3024151623249054\n",
      "Epoch 216: curr_epoch_loss=0.3302324414253235\n",
      "Epoch 217: curr_epoch_loss=0.3102741241455078\n",
      "Epoch 218: curr_epoch_loss=0.31472378969192505\n",
      "Epoch 219: curr_epoch_loss=0.32290884852409363\n",
      "Epoch 220: curr_epoch_loss=0.2954105734825134\n",
      "Epoch 221: curr_epoch_loss=0.3037368059158325\n",
      "Epoch 222: curr_epoch_loss=0.3369964063167572\n",
      "Epoch 223: curr_epoch_loss=0.3440634310245514\n",
      "Epoch 224: curr_epoch_loss=0.30484840273857117\n",
      "Epoch 225: curr_epoch_loss=0.3518015146255493\n",
      "Epoch 226: curr_epoch_loss=0.3450300693511963\n",
      "Epoch 227: curr_epoch_loss=0.2891956567764282\n",
      "Epoch 228: curr_epoch_loss=0.29494452476501465\n",
      "Epoch 229: curr_epoch_loss=0.3040933907032013\n",
      "Epoch 230: curr_epoch_loss=0.33177420496940613\n",
      "Epoch 231: curr_epoch_loss=0.3227877914905548\n",
      "Epoch 232: curr_epoch_loss=0.29442963004112244\n",
      "Epoch 233: curr_epoch_loss=0.3131347894668579\n",
      "Epoch 234: curr_epoch_loss=0.2893175482749939\n",
      "Epoch 235: curr_epoch_loss=0.29349690675735474\n",
      "Epoch 236: curr_epoch_loss=0.33434656262397766\n",
      "Epoch 237: curr_epoch_loss=0.31344717741012573\n",
      "Epoch 238: curr_epoch_loss=0.33496367931365967\n",
      "Epoch 239: curr_epoch_loss=0.2952539324760437\n",
      "Epoch 240: curr_epoch_loss=0.31772661209106445\n",
      "Epoch 241: curr_epoch_loss=0.29647544026374817\n",
      "Epoch 242: curr_epoch_loss=0.32668814063072205\n",
      "Epoch 243: curr_epoch_loss=0.30296313762664795\n",
      "Epoch 244: curr_epoch_loss=0.31109076738357544\n",
      "Epoch 245: curr_epoch_loss=0.29299265146255493\n",
      "Epoch 246: curr_epoch_loss=0.29510343074798584\n",
      "Epoch 247: curr_epoch_loss=0.32210099697113037\n",
      "Epoch 248: curr_epoch_loss=0.3082202672958374\n",
      "Epoch 249: curr_epoch_loss=0.31589049100875854\n",
      "Epoch 250: curr_epoch_loss=0.29557669162750244\n",
      "Epoch 251: curr_epoch_loss=0.2976300120353699\n",
      "Epoch 252: curr_epoch_loss=0.3173481822013855\n",
      "Epoch 253: curr_epoch_loss=0.3282695710659027\n",
      "Epoch 254: curr_epoch_loss=0.31005167961120605\n",
      "Epoch 255: curr_epoch_loss=0.29972243309020996\n",
      "Epoch 256: curr_epoch_loss=0.3234027624130249\n",
      "Epoch 257: curr_epoch_loss=0.31756338477134705\n",
      "Epoch 258: curr_epoch_loss=0.3225885033607483\n",
      "Epoch 259: curr_epoch_loss=0.3188617527484894\n",
      "Epoch 260: curr_epoch_loss=0.31653720140457153\n",
      "Epoch 261: curr_epoch_loss=0.31932130455970764\n",
      "Epoch 262: curr_epoch_loss=0.3026113212108612\n",
      "Epoch 263: curr_epoch_loss=0.30825233459472656\n",
      "Epoch 264: curr_epoch_loss=0.32139861583709717\n",
      "Epoch 265: curr_epoch_loss=0.31557637453079224\n",
      "Epoch 266: curr_epoch_loss=0.30923086404800415\n",
      "Epoch 267: curr_epoch_loss=0.29709094762802124\n",
      "Epoch 268: curr_epoch_loss=0.31115153431892395\n",
      "Epoch 269: curr_epoch_loss=0.301727831363678\n",
      "Epoch 270: curr_epoch_loss=0.3009999990463257\n",
      "Epoch 271: curr_epoch_loss=0.2967429757118225\n",
      "Epoch 272: curr_epoch_loss=0.30312442779541016\n",
      "Epoch 273: curr_epoch_loss=0.3205685019493103\n",
      "Epoch 274: curr_epoch_loss=0.28426772356033325\n",
      "Epoch 275: curr_epoch_loss=0.3037479519844055\n",
      "Epoch 276: curr_epoch_loss=0.28212404251098633\n",
      "Epoch 277: curr_epoch_loss=0.3089243769645691\n",
      "Epoch 278: curr_epoch_loss=0.30730023980140686\n",
      "Epoch 279: curr_epoch_loss=0.30335408449172974\n",
      "Epoch 280: curr_epoch_loss=0.28927457332611084\n",
      "Epoch 281: curr_epoch_loss=0.30203574895858765\n",
      "Epoch 282: curr_epoch_loss=0.31070631742477417\n",
      "Epoch 283: curr_epoch_loss=0.31657731533050537\n",
      "Epoch 284: curr_epoch_loss=0.3039030134677887\n",
      "Epoch 285: curr_epoch_loss=0.2997066080570221\n",
      "Epoch 286: curr_epoch_loss=0.3107423484325409\n",
      "Epoch 287: curr_epoch_loss=0.3341166377067566\n",
      "Epoch 288: curr_epoch_loss=0.34479182958602905\n",
      "Epoch 289: curr_epoch_loss=0.30266958475112915\n",
      "Epoch 290: curr_epoch_loss=0.2973746359348297\n",
      "Epoch 291: curr_epoch_loss=0.28784406185150146\n",
      "Epoch 292: curr_epoch_loss=0.3199300169944763\n",
      "Epoch 293: curr_epoch_loss=0.30569881200790405\n",
      "Epoch 294: curr_epoch_loss=0.31044530868530273\n",
      "Epoch 295: curr_epoch_loss=0.29762640595436096\n",
      "Epoch 296: curr_epoch_loss=0.2910758852958679\n",
      "Epoch 297: curr_epoch_loss=0.2932260036468506\n",
      "Epoch 298: curr_epoch_loss=0.28626978397369385\n",
      "Epoch 299: curr_epoch_loss=0.3161432147026062\n",
      "Epoch 300: curr_epoch_loss=0.31808334589004517\n",
      "Epoch 301: curr_epoch_loss=0.3168773055076599\n",
      "Epoch 302: curr_epoch_loss=0.32411229610443115\n",
      "Epoch 303: curr_epoch_loss=0.3007974326610565\n",
      "Epoch 304: curr_epoch_loss=0.3052240312099457\n",
      "Epoch 305: curr_epoch_loss=0.30766260623931885\n",
      "Epoch 306: curr_epoch_loss=0.3245551586151123\n",
      "Epoch 307: curr_epoch_loss=0.31385111808776855\n",
      "Epoch 308: curr_epoch_loss=0.2882690727710724\n",
      "Epoch 309: curr_epoch_loss=0.29859477281570435\n",
      "Epoch 310: curr_epoch_loss=0.30270516872406006\n",
      "Epoch 311: curr_epoch_loss=0.3005818724632263\n",
      "Epoch 312: curr_epoch_loss=0.3132992386817932\n",
      "Epoch 313: curr_epoch_loss=0.30848240852355957\n",
      "Epoch 314: curr_epoch_loss=0.31351906061172485\n",
      "Epoch 315: curr_epoch_loss=0.31783267855644226\n",
      "Epoch 316: curr_epoch_loss=0.3176654875278473\n",
      "Epoch 317: curr_epoch_loss=0.3093932867050171\n",
      "Epoch 318: curr_epoch_loss=0.31554901599884033\n",
      "Epoch 319: curr_epoch_loss=0.33013415336608887\n",
      "Epoch 320: curr_epoch_loss=0.29406875371932983\n",
      "Epoch 321: curr_epoch_loss=0.3202701508998871\n",
      "Epoch 322: curr_epoch_loss=0.3143594264984131\n",
      "Epoch 323: curr_epoch_loss=0.3298463225364685\n",
      "Epoch 324: curr_epoch_loss=0.3308907151222229\n",
      "Epoch 325: curr_epoch_loss=0.3228578567504883\n",
      "Epoch 326: curr_epoch_loss=0.31740814447402954\n",
      "Epoch 327: curr_epoch_loss=0.34475529193878174\n",
      "Epoch 328: curr_epoch_loss=0.353782594203949\n",
      "Epoch 329: curr_epoch_loss=0.3351919949054718\n",
      "Epoch 330: curr_epoch_loss=0.2966628968715668\n",
      "Epoch 331: curr_epoch_loss=0.3143342435359955\n",
      "Epoch 332: curr_epoch_loss=0.3248346447944641\n",
      "Epoch 333: curr_epoch_loss=0.29363420605659485\n",
      "Epoch 334: curr_epoch_loss=0.31716257333755493\n",
      "Epoch 335: curr_epoch_loss=0.3178660273551941\n",
      "Epoch 336: curr_epoch_loss=0.3324771523475647\n",
      "Epoch 337: curr_epoch_loss=0.3199746608734131\n",
      "Epoch 338: curr_epoch_loss=0.2989305853843689\n",
      "Epoch 339: curr_epoch_loss=0.32133057713508606\n",
      "Epoch 340: curr_epoch_loss=0.3300793766975403\n",
      "Epoch 341: curr_epoch_loss=0.310583233833313\n",
      "Epoch 342: curr_epoch_loss=0.31711143255233765\n",
      "Epoch 343: curr_epoch_loss=0.31133466958999634\n",
      "Epoch 344: curr_epoch_loss=0.3243103325366974\n",
      "Epoch 345: curr_epoch_loss=0.30604949593544006\n",
      "Epoch 346: curr_epoch_loss=0.3003307282924652\n",
      "Epoch 347: curr_epoch_loss=0.3046484589576721\n",
      "Epoch 348: curr_epoch_loss=0.31583449244499207\n",
      "Epoch 349: curr_epoch_loss=0.30439555644989014\n",
      "Epoch 350: curr_epoch_loss=0.3212517499923706\n",
      "Epoch 351: curr_epoch_loss=0.30034857988357544\n",
      "Epoch 352: curr_epoch_loss=0.2912726402282715\n",
      "Epoch 353: curr_epoch_loss=0.3266936242580414\n",
      "Epoch 354: curr_epoch_loss=0.3033328652381897\n",
      "Epoch 355: curr_epoch_loss=0.30119603872299194\n",
      "Epoch 356: curr_epoch_loss=0.30461159348487854\n",
      "Epoch 357: curr_epoch_loss=0.32357779145240784\n",
      "Epoch 358: curr_epoch_loss=0.2894415259361267\n",
      "Epoch 359: curr_epoch_loss=0.3144874572753906\n",
      "Epoch 360: curr_epoch_loss=0.30546605587005615\n",
      "Epoch 361: curr_epoch_loss=0.32324859499931335\n",
      "Epoch 362: curr_epoch_loss=0.3146016597747803\n",
      "Epoch 363: curr_epoch_loss=0.29889020323753357\n",
      "Epoch 364: curr_epoch_loss=0.3030899167060852\n",
      "Epoch 365: curr_epoch_loss=0.31258004903793335\n",
      "Epoch 366: curr_epoch_loss=0.3348691463470459\n",
      "Epoch 367: curr_epoch_loss=0.3002622127532959\n",
      "Epoch 368: curr_epoch_loss=0.29870137572288513\n",
      "Epoch 369: curr_epoch_loss=0.3056463301181793\n",
      "Epoch 370: curr_epoch_loss=0.3380632996559143\n",
      "Epoch 371: curr_epoch_loss=0.3115924298763275\n",
      "Epoch 372: curr_epoch_loss=0.308601051568985\n",
      "Epoch 373: curr_epoch_loss=0.3223533034324646\n",
      "Epoch 374: curr_epoch_loss=0.3015056848526001\n",
      "Epoch 375: curr_epoch_loss=0.2973649799823761\n",
      "Epoch 376: curr_epoch_loss=0.2947593033313751\n",
      "Epoch 377: curr_epoch_loss=0.33292481303215027\n",
      "Epoch 378: curr_epoch_loss=0.3153991103172302\n",
      "Epoch 379: curr_epoch_loss=0.318523108959198\n",
      "Epoch 380: curr_epoch_loss=0.31269362568855286\n",
      "Epoch 381: curr_epoch_loss=0.30438339710235596\n",
      "Epoch 382: curr_epoch_loss=0.3032594323158264\n",
      "Epoch 383: curr_epoch_loss=0.3065207004547119\n",
      "Epoch 384: curr_epoch_loss=0.3107447028160095\n",
      "Epoch 385: curr_epoch_loss=0.3102533221244812\n",
      "Epoch 386: curr_epoch_loss=0.30347177386283875\n",
      "Epoch 387: curr_epoch_loss=0.322268545627594\n",
      "Epoch 388: curr_epoch_loss=0.34711742401123047\n",
      "Epoch 389: curr_epoch_loss=0.29092517495155334\n",
      "Epoch 390: curr_epoch_loss=0.2858744263648987\n",
      "Epoch 391: curr_epoch_loss=0.3379479646682739\n",
      "Epoch 392: curr_epoch_loss=0.31881022453308105\n",
      "Epoch 393: curr_epoch_loss=0.30797961354255676\n",
      "Epoch 394: curr_epoch_loss=0.30417245626449585\n",
      "Epoch 395: curr_epoch_loss=0.30389973521232605\n",
      "Epoch 396: curr_epoch_loss=0.3007550835609436\n",
      "Epoch 397: curr_epoch_loss=0.3005681037902832\n",
      "Epoch 398: curr_epoch_loss=0.29864436388015747\n",
      "Epoch 399: curr_epoch_loss=0.3016849756240845\n",
      "Epoch 400: curr_epoch_loss=0.2973267436027527\n",
      "Epoch 401: curr_epoch_loss=0.3085917830467224\n",
      "Epoch 402: curr_epoch_loss=0.33714622259140015\n",
      "Epoch 403: curr_epoch_loss=0.29979610443115234\n",
      "Epoch 404: curr_epoch_loss=0.30598974227905273\n",
      "Epoch 405: curr_epoch_loss=0.3309364914894104\n",
      "Epoch 406: curr_epoch_loss=0.3305647373199463\n",
      "Epoch 407: curr_epoch_loss=0.3163306415081024\n",
      "Epoch 408: curr_epoch_loss=0.31248903274536133\n",
      "Epoch 409: curr_epoch_loss=0.32094669342041016\n",
      "Epoch 410: curr_epoch_loss=0.31657636165618896\n",
      "Epoch 411: curr_epoch_loss=0.2881690263748169\n",
      "Epoch 412: curr_epoch_loss=0.3105276823043823\n",
      "Epoch 413: curr_epoch_loss=0.31731241941452026\n",
      "Epoch 414: curr_epoch_loss=0.30027028918266296\n",
      "Epoch 415: curr_epoch_loss=0.31646642088890076\n",
      "Epoch 416: curr_epoch_loss=0.3034660220146179\n",
      "Epoch 417: curr_epoch_loss=0.30099159479141235\n",
      "Epoch 418: curr_epoch_loss=0.3105005621910095\n",
      "Epoch 419: curr_epoch_loss=0.3099328875541687\n",
      "Epoch 420: curr_epoch_loss=0.3034842014312744\n",
      "Epoch 421: curr_epoch_loss=0.3056976795196533\n",
      "Epoch 422: curr_epoch_loss=0.29863637685775757\n",
      "Epoch 423: curr_epoch_loss=0.29846471548080444\n",
      "Epoch 424: curr_epoch_loss=0.3045497536659241\n",
      "Epoch 425: curr_epoch_loss=0.30895888805389404\n",
      "Epoch 426: curr_epoch_loss=0.3123408555984497\n",
      "Epoch 427: curr_epoch_loss=0.32231566309928894\n",
      "Epoch 428: curr_epoch_loss=0.3352973163127899\n",
      "Epoch 429: curr_epoch_loss=0.3026672899723053\n",
      "Epoch 430: curr_epoch_loss=0.2991158366203308\n",
      "Epoch 431: curr_epoch_loss=0.31075602769851685\n",
      "Epoch 432: curr_epoch_loss=0.3096758723258972\n",
      "Epoch 433: curr_epoch_loss=0.31369084119796753\n",
      "Epoch 434: curr_epoch_loss=0.35316938161849976\n",
      "Epoch 435: curr_epoch_loss=0.30389976501464844\n",
      "Epoch 436: curr_epoch_loss=0.32291164994239807\n",
      "Epoch 437: curr_epoch_loss=0.31943532824516296\n",
      "Epoch 438: curr_epoch_loss=0.3116337060928345\n",
      "Epoch 439: curr_epoch_loss=0.30448082089424133\n",
      "Epoch 440: curr_epoch_loss=0.3017446994781494\n",
      "Epoch 441: curr_epoch_loss=0.3100491166114807\n",
      "Epoch 442: curr_epoch_loss=0.3114955425262451\n",
      "Epoch 443: curr_epoch_loss=0.29501163959503174\n",
      "Epoch 444: curr_epoch_loss=0.3108257055282593\n",
      "Epoch 445: curr_epoch_loss=0.3102208971977234\n",
      "Epoch 446: curr_epoch_loss=0.32478243112564087\n",
      "Epoch 447: curr_epoch_loss=0.2910563349723816\n",
      "Epoch 448: curr_epoch_loss=0.2954779863357544\n",
      "Epoch 449: curr_epoch_loss=0.2946263253688812\n",
      "Epoch 450: curr_epoch_loss=0.30483418703079224\n",
      "Epoch 451: curr_epoch_loss=0.32629460096359253\n",
      "Epoch 452: curr_epoch_loss=0.3131575584411621\n",
      "Epoch 453: curr_epoch_loss=0.3091469407081604\n",
      "Epoch 454: curr_epoch_loss=0.3048175871372223\n",
      "Epoch 455: curr_epoch_loss=0.2972644567489624\n",
      "Epoch 456: curr_epoch_loss=0.3118622601032257\n",
      "Epoch 457: curr_epoch_loss=0.3092769384384155\n",
      "Epoch 458: curr_epoch_loss=0.3085867762565613\n",
      "Epoch 459: curr_epoch_loss=0.3089657425880432\n",
      "Epoch 460: curr_epoch_loss=0.312385618686676\n",
      "Epoch 461: curr_epoch_loss=0.31562432646751404\n",
      "Epoch 462: curr_epoch_loss=0.31354111433029175\n",
      "Epoch 463: curr_epoch_loss=0.32058119773864746\n",
      "Epoch 464: curr_epoch_loss=0.31230637431144714\n",
      "Epoch 465: curr_epoch_loss=0.3000386953353882\n",
      "Epoch 466: curr_epoch_loss=0.31745612621307373\n",
      "Epoch 467: curr_epoch_loss=0.3147164583206177\n",
      "Epoch 468: curr_epoch_loss=0.30159974098205566\n",
      "Epoch 469: curr_epoch_loss=0.29965776205062866\n",
      "Epoch 470: curr_epoch_loss=0.3055276870727539\n",
      "Epoch 471: curr_epoch_loss=0.31535062193870544\n",
      "Epoch 472: curr_epoch_loss=0.3104240894317627\n",
      "Epoch 473: curr_epoch_loss=0.3028530180454254\n",
      "Epoch 474: curr_epoch_loss=0.30163484811782837\n",
      "Epoch 475: curr_epoch_loss=0.3181591033935547\n",
      "Epoch 476: curr_epoch_loss=0.3172405958175659\n",
      "Epoch 477: curr_epoch_loss=0.31505876779556274\n",
      "Epoch 478: curr_epoch_loss=0.3130957782268524\n",
      "Epoch 479: curr_epoch_loss=0.29143422842025757\n",
      "Epoch 480: curr_epoch_loss=0.3360138535499573\n",
      "Epoch 481: curr_epoch_loss=0.31578952074050903\n",
      "Epoch 482: curr_epoch_loss=0.30715513229370117\n",
      "Epoch 483: curr_epoch_loss=0.3275247812271118\n",
      "Epoch 484: curr_epoch_loss=0.3198709487915039\n",
      "Epoch 485: curr_epoch_loss=0.31391632556915283\n",
      "Epoch 486: curr_epoch_loss=0.3026580810546875\n",
      "Epoch 487: curr_epoch_loss=0.3179863691329956\n",
      "Epoch 488: curr_epoch_loss=0.32179373502731323\n",
      "Epoch 489: curr_epoch_loss=0.3038521111011505\n",
      "Epoch 490: curr_epoch_loss=0.32130318880081177\n",
      "Epoch 491: curr_epoch_loss=0.29794842004776\n",
      "Epoch 492: curr_epoch_loss=0.3123854994773865\n",
      "Epoch 493: curr_epoch_loss=0.29264265298843384\n",
      "Epoch 494: curr_epoch_loss=0.30202367901802063\n",
      "Epoch 495: curr_epoch_loss=0.31777384877204895\n",
      "Epoch 496: curr_epoch_loss=0.30031755566596985\n",
      "Epoch 497: curr_epoch_loss=0.328113853931427\n",
      "Epoch 498: curr_epoch_loss=0.3100244700908661\n",
      "Epoch 499: curr_epoch_loss=0.31359148025512695\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = SentenceSimilarityCNN(train_dataset.get_max_sentence_length())\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)\n",
    "n_epochs=500\n",
    "def train(train_loader, n_epochs=n_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        curr_epoch_loss = []\n",
    "        for sentence_pairs, y in train_loader:\n",
    "            y_hat = model(sentence_pairs)\n",
    "            # print(\"training\")\n",
    "            # print(y_hat)\n",
    "            # print(y)\n",
    "            # print(\"======\")\n",
    "            loss = criterion(y_hat, y.float())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            curr_epoch_loss.append(loss.cpu().data.numpy())\n",
    "\n",
    "        print(f\"Epoch {epoch}: curr_epoch_loss={np.mean(curr_epoch_loss)}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "model = train(train_dataloader)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1844, 0.1844, 0.1844, 0.1844, 0.1844, 0.1769, 0.1844, 0.1844, 0.1844,\n",
      "        0.1844, 0.1851, 0.1806, 0.2096, 0.1844, 0.1844, 0.1835, 0.1844, 0.1844,\n",
      "        0.1575, 0.1667, 0.1869, 0.1844, 0.1844, 0.1868, 0.1844, 0.2586, 0.1844,\n",
      "        0.1844, 0.1844, 0.1754, 0.1757, 0.1879, 0.1844, 0.2246, 0.1844, 0.1844,\n",
      "        0.1844, 0.1844, 0.1844, 0.1844, 0.1844, 0.1844, 0.1948, 0.1844, 0.1844,\n",
      "        0.1844, 0.1844, 0.1844, 0.2117, 0.1844, 0.1844, 0.1844, 0.1688, 0.1844,\n",
      "        0.1948, 0.1958, 0.1741, 0.1844, 0.1844, 0.1971, 0.1867, 0.1844, 0.1844,\n",
      "        0.1844], grad_fn=<ExpBackward0>)\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "tensor([1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
      "        0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "def eval_model(model, test_dataloader):\n",
    "    model.eval()\n",
    "    for sentence_pairs, y in test_dataloader:\n",
    "        y_hat = model(sentence_pairs)\n",
    "        print(y_hat)\n",
    "        y_pred = torch.zeros(y_hat.shape)\n",
    "        y_pred = (y_hat > 0.7).int()\n",
    "        print(y_pred)\n",
    "        print(y)\n",
    "        break\n",
    "\n",
    "eval_model(model, train_dataloader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SentenceSimilarityCNN2(nn.Module):\n",
    "    def __init__(self, embedding_dim, num_filters, filter_size, hidden_dim, dropout_prob=0.5):\n",
    "        super(SentenceSimilarityCNN2, self).__init__()\n",
    "        #self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # self.conv_layers = nn.ModuleList([\n",
    "        #     nn.Conv1d(in_channels=embedding_dim, out_channels=num_filters, kernel_size=fs)\n",
    "        #     for fs in filter_sizes\n",
    "        # ])\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=embedding_dim, out_channels=num_filters, kernel_size=filter_size)\n",
    "        self.fc1 = nn.Linear(num_filters , hidden_dim)\n",
    "\n",
    "        #self.fc1 = nn.Linear(num_filters * len(filter_size), hidden_dim)\n",
    "        #self.dropout = nn.Dropout(dropout_prob)\n",
    "        #self.fc2 = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, input1_embedded, input2_embedded):\n",
    "        # Embedding\n",
    "        #input1_embedded = self.embedding(input1)\n",
    "        #input2_embedded = self.embedding(input2)\n",
    "\n",
    "        # Convolution\n",
    "        #input1_conv = [F.relu(conv(input1_embedded.permute(0, 2, 1))) for conv in self.conv_layers]\n",
    "        #input2_conv = [F.relu(conv(input2_embedded.permute(0, 2, 1))) for conv in self.conv_layers]\n",
    "\n",
    "        input1_embedded = self.conv1(input1_embedded.permute(0, 2, 1))\n",
    "        input2_embedded = self.conv1(input2_embedded.permute(0, 2, 1))\n",
    "        #print(input1_embedded.shape)\n",
    "\n",
    "\n",
    "        input1_embedded = F.max_pool1d(input1_embedded, input1_embedded.shape[2]).squeeze(2)\n",
    "        input2_embedded = F.max_pool1d(input2_embedded, input2_embedded.shape[2]).squeeze(2)\n",
    "        #print(input1_embedded.shape)\n",
    "\n",
    "        input1_embedded = self.fc1(input1_embedded)\n",
    "        input2_embedded = self.fc1(input2_embedded)\n",
    "        #print(input1_embedded.shape)\n",
    "\n",
    "        man_dist = torch.sum(torch.abs(input1_embedded - input2_embedded), axis=1)\n",
    "        # sentence1_mean = torch.mean(x1, axis=1)\n",
    "        # sentence2_mean = torch.mean(x2, axis=1)\n",
    "        # man_dist = torch.sum(torch.abs(sentence1_mean - sentence2_mean), axis=1)\n",
    "        # print(man_dist.shape)\n",
    "\n",
    "        return torch.exp(-man_dist)\n",
    "\n",
    "\n",
    "        #input2_embedded = self.conv1(input2_embedded.permute(0, 2, 1))\n",
    "\n",
    "\n",
    "        # Max pooling\n",
    "        # input1_pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in input1_conv]\n",
    "        # input2_pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in input2_conv]\n",
    "        #\n",
    "        # # Concatenate and flatten\n",
    "        # input1_concat = torch.cat(input1_pooled, dim=1)\n",
    "        # input2_concat = torch.cat(input2_pooled, dim=1)\n",
    "        #\n",
    "        # # Concatenate the two sentence representations\n",
    "        # sentence_similarity = torch.cat([input1_concat, input2_concat], dim=1)\n",
    "        #\n",
    "        # # Dense layers\n",
    "        # #sentence_similarity = self.dropout(F.relu(self.fc1(sentence_similarity)))\n",
    "        # #sentence_similarity = self.fc2(sentence_similarity)\n",
    "        #\n",
    "        # return torch.sigmoid(sentence_similarity)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: curr_epoch_loss=0.24314576387405396\n",
      "Epoch 1: curr_epoch_loss=0.22970780730247498\n",
      "Epoch 2: curr_epoch_loss=0.2272256314754486\n",
      "Epoch 3: curr_epoch_loss=0.22701096534729004\n",
      "Epoch 4: curr_epoch_loss=0.22742003202438354\n",
      "Epoch 5: curr_epoch_loss=0.23069681227207184\n",
      "Epoch 6: curr_epoch_loss=0.22767218947410583\n",
      "Epoch 7: curr_epoch_loss=0.2233491837978363\n",
      "Epoch 8: curr_epoch_loss=0.22412371635437012\n",
      "Epoch 9: curr_epoch_loss=0.22176901996135712\n",
      "Epoch 10: curr_epoch_loss=0.21956606209278107\n",
      "Epoch 11: curr_epoch_loss=0.21926018595695496\n",
      "Epoch 12: curr_epoch_loss=0.22022682428359985\n",
      "Epoch 13: curr_epoch_loss=0.21991559863090515\n",
      "Epoch 14: curr_epoch_loss=0.21857494115829468\n",
      "Epoch 15: curr_epoch_loss=0.22100526094436646\n",
      "Epoch 16: curr_epoch_loss=0.2205694019794464\n",
      "Epoch 17: curr_epoch_loss=0.21965289115905762\n",
      "Epoch 18: curr_epoch_loss=0.21807214617729187\n",
      "Epoch 19: curr_epoch_loss=0.21940770745277405\n",
      "Epoch 20: curr_epoch_loss=0.21849504113197327\n",
      "Epoch 21: curr_epoch_loss=0.21697071194648743\n",
      "Epoch 22: curr_epoch_loss=0.21506014466285706\n",
      "Epoch 23: curr_epoch_loss=0.21489858627319336\n",
      "Epoch 24: curr_epoch_loss=0.2155512273311615\n",
      "Epoch 25: curr_epoch_loss=0.21634793281555176\n",
      "Epoch 26: curr_epoch_loss=0.2171299159526825\n",
      "Epoch 27: curr_epoch_loss=0.2159269154071808\n",
      "Epoch 28: curr_epoch_loss=0.21434386074543\n",
      "Epoch 29: curr_epoch_loss=0.21304285526275635\n",
      "Epoch 30: curr_epoch_loss=0.21442736685276031\n",
      "Epoch 31: curr_epoch_loss=0.21289560198783875\n",
      "Epoch 32: curr_epoch_loss=0.2121884524822235\n",
      "Epoch 33: curr_epoch_loss=0.2124631404876709\n",
      "Epoch 34: curr_epoch_loss=0.21103772521018982\n",
      "Epoch 35: curr_epoch_loss=0.21184709668159485\n",
      "Epoch 36: curr_epoch_loss=0.2109728455543518\n",
      "Epoch 37: curr_epoch_loss=0.2094046026468277\n",
      "Epoch 38: curr_epoch_loss=0.2092875987291336\n",
      "Epoch 39: curr_epoch_loss=0.2090337872505188\n",
      "Epoch 40: curr_epoch_loss=0.20823471248149872\n",
      "Epoch 41: curr_epoch_loss=0.20755377411842346\n",
      "Epoch 42: curr_epoch_loss=0.20740145444869995\n",
      "Epoch 43: curr_epoch_loss=0.20765241980552673\n",
      "Epoch 44: curr_epoch_loss=0.20687812566757202\n",
      "Epoch 45: curr_epoch_loss=0.20670823752880096\n",
      "Epoch 46: curr_epoch_loss=0.206250861287117\n",
      "Epoch 47: curr_epoch_loss=0.20585916936397552\n",
      "Epoch 48: curr_epoch_loss=0.20610499382019043\n",
      "Epoch 49: curr_epoch_loss=0.20581579208374023\n",
      "Epoch 50: curr_epoch_loss=0.20579054951667786\n",
      "Epoch 51: curr_epoch_loss=0.2052047848701477\n",
      "Epoch 52: curr_epoch_loss=0.20528385043144226\n",
      "Epoch 53: curr_epoch_loss=0.204698845744133\n",
      "Epoch 54: curr_epoch_loss=0.2045091688632965\n",
      "Epoch 55: curr_epoch_loss=0.20578832924365997\n",
      "Epoch 56: curr_epoch_loss=0.204132080078125\n",
      "Epoch 57: curr_epoch_loss=0.2037077248096466\n",
      "Epoch 58: curr_epoch_loss=0.2030945122241974\n",
      "Epoch 59: curr_epoch_loss=0.2034575343132019\n",
      "Epoch 60: curr_epoch_loss=0.2032099962234497\n",
      "Epoch 61: curr_epoch_loss=0.20277103781700134\n",
      "Epoch 62: curr_epoch_loss=0.20227620005607605\n",
      "Epoch 63: curr_epoch_loss=0.20428070425987244\n",
      "Epoch 64: curr_epoch_loss=0.20239850878715515\n",
      "Epoch 65: curr_epoch_loss=0.20295605063438416\n",
      "Epoch 66: curr_epoch_loss=0.20249612629413605\n",
      "Epoch 67: curr_epoch_loss=0.20451194047927856\n",
      "Epoch 68: curr_epoch_loss=0.20248901844024658\n",
      "Epoch 69: curr_epoch_loss=0.2019791305065155\n",
      "Epoch 70: curr_epoch_loss=0.201908677816391\n",
      "Epoch 71: curr_epoch_loss=0.20138046145439148\n",
      "Epoch 72: curr_epoch_loss=0.20137134194374084\n",
      "Epoch 73: curr_epoch_loss=0.2014441043138504\n",
      "Epoch 74: curr_epoch_loss=0.20136615633964539\n",
      "Epoch 75: curr_epoch_loss=0.20115351676940918\n",
      "Epoch 76: curr_epoch_loss=0.20139417052268982\n",
      "Epoch 77: curr_epoch_loss=0.2007569968700409\n",
      "Epoch 78: curr_epoch_loss=0.2016041874885559\n",
      "Epoch 79: curr_epoch_loss=0.2013324797153473\n",
      "Epoch 80: curr_epoch_loss=0.2012116014957428\n",
      "Epoch 81: curr_epoch_loss=0.20105262100696564\n",
      "Epoch 82: curr_epoch_loss=0.20095181465148926\n",
      "Epoch 83: curr_epoch_loss=0.20111732184886932\n",
      "Epoch 84: curr_epoch_loss=0.2000037431716919\n",
      "Epoch 85: curr_epoch_loss=0.20037584006786346\n",
      "Epoch 86: curr_epoch_loss=0.2004716396331787\n",
      "Epoch 87: curr_epoch_loss=0.20028838515281677\n",
      "Epoch 88: curr_epoch_loss=0.19910340011119843\n",
      "Epoch 89: curr_epoch_loss=0.19913828372955322\n",
      "Epoch 90: curr_epoch_loss=0.19856134057044983\n",
      "Epoch 91: curr_epoch_loss=0.1987474411725998\n",
      "Epoch 92: curr_epoch_loss=0.19874891638755798\n",
      "Epoch 93: curr_epoch_loss=0.19889096915721893\n",
      "Epoch 94: curr_epoch_loss=0.19966775178909302\n",
      "Epoch 95: curr_epoch_loss=0.19884955883026123\n",
      "Epoch 96: curr_epoch_loss=0.1987837553024292\n",
      "Epoch 97: curr_epoch_loss=0.198367178440094\n",
      "Epoch 98: curr_epoch_loss=0.19823867082595825\n",
      "Epoch 99: curr_epoch_loss=0.19879430532455444\n",
      "Epoch 100: curr_epoch_loss=0.199423685669899\n",
      "Epoch 101: curr_epoch_loss=0.20041611790657043\n",
      "Epoch 102: curr_epoch_loss=0.19968070089817047\n",
      "Epoch 103: curr_epoch_loss=0.19933092594146729\n",
      "Epoch 104: curr_epoch_loss=0.20035147666931152\n",
      "Epoch 105: curr_epoch_loss=0.1992945373058319\n",
      "Epoch 106: curr_epoch_loss=0.19935308396816254\n",
      "Epoch 107: curr_epoch_loss=0.19972145557403564\n",
      "Epoch 108: curr_epoch_loss=0.20138472318649292\n",
      "Epoch 109: curr_epoch_loss=0.1988879293203354\n",
      "Epoch 110: curr_epoch_loss=0.20052886009216309\n",
      "Epoch 111: curr_epoch_loss=0.19831186532974243\n",
      "Epoch 112: curr_epoch_loss=0.19929912686347961\n",
      "Epoch 113: curr_epoch_loss=0.19918526709079742\n",
      "Epoch 114: curr_epoch_loss=0.19965830445289612\n",
      "Epoch 115: curr_epoch_loss=0.1993749588727951\n",
      "Epoch 116: curr_epoch_loss=0.19874092936515808\n",
      "Epoch 117: curr_epoch_loss=0.19970916211605072\n",
      "Epoch 118: curr_epoch_loss=0.19865313172340393\n",
      "Epoch 119: curr_epoch_loss=0.1995793879032135\n",
      "Epoch 120: curr_epoch_loss=0.19888214766979218\n",
      "Epoch 121: curr_epoch_loss=0.19862185418605804\n",
      "Epoch 122: curr_epoch_loss=0.1985500007867813\n",
      "Epoch 123: curr_epoch_loss=0.1996442675590515\n",
      "Epoch 124: curr_epoch_loss=0.19731152057647705\n",
      "Epoch 125: curr_epoch_loss=0.19742955267429352\n",
      "Epoch 126: curr_epoch_loss=0.19635051488876343\n",
      "Epoch 127: curr_epoch_loss=0.19708357751369476\n",
      "Epoch 128: curr_epoch_loss=0.1993538737297058\n",
      "Epoch 129: curr_epoch_loss=0.19874116778373718\n",
      "Epoch 130: curr_epoch_loss=0.1965726763010025\n",
      "Epoch 131: curr_epoch_loss=0.1975795179605484\n",
      "Epoch 132: curr_epoch_loss=0.19669969379901886\n",
      "Epoch 133: curr_epoch_loss=0.1966700255870819\n",
      "Epoch 134: curr_epoch_loss=0.19639012217521667\n",
      "Epoch 135: curr_epoch_loss=0.19663399457931519\n",
      "Epoch 136: curr_epoch_loss=0.19734078645706177\n",
      "Epoch 137: curr_epoch_loss=0.19638940691947937\n",
      "Epoch 138: curr_epoch_loss=0.19594302773475647\n",
      "Epoch 139: curr_epoch_loss=0.19628167152404785\n",
      "Epoch 140: curr_epoch_loss=0.19607144594192505\n",
      "Epoch 141: curr_epoch_loss=0.19672608375549316\n",
      "Epoch 142: curr_epoch_loss=0.19642242789268494\n",
      "Epoch 143: curr_epoch_loss=0.19521769881248474\n",
      "Epoch 144: curr_epoch_loss=0.19465413689613342\n",
      "Epoch 145: curr_epoch_loss=0.19483670592308044\n",
      "Epoch 146: curr_epoch_loss=0.1968279778957367\n",
      "Epoch 147: curr_epoch_loss=0.19482921063899994\n",
      "Epoch 148: curr_epoch_loss=0.19558711349964142\n",
      "Epoch 149: curr_epoch_loss=0.1936374306678772\n",
      "Epoch 150: curr_epoch_loss=0.19477581977844238\n",
      "Epoch 151: curr_epoch_loss=0.1933603286743164\n",
      "Epoch 152: curr_epoch_loss=0.19368621706962585\n",
      "Epoch 153: curr_epoch_loss=0.19357700645923615\n",
      "Epoch 154: curr_epoch_loss=0.19381122291088104\n",
      "Epoch 155: curr_epoch_loss=0.19383877515792847\n",
      "Epoch 156: curr_epoch_loss=0.1928565502166748\n",
      "Epoch 157: curr_epoch_loss=0.19334685802459717\n",
      "Epoch 158: curr_epoch_loss=0.1933269500732422\n",
      "Epoch 159: curr_epoch_loss=0.1949557363986969\n",
      "Epoch 160: curr_epoch_loss=0.19280150532722473\n",
      "Epoch 161: curr_epoch_loss=0.19329482316970825\n",
      "Epoch 162: curr_epoch_loss=0.19450336694717407\n",
      "Epoch 163: curr_epoch_loss=0.19165676832199097\n",
      "Epoch 164: curr_epoch_loss=0.1925221085548401\n",
      "Epoch 165: curr_epoch_loss=0.19230806827545166\n",
      "Epoch 166: curr_epoch_loss=0.19256365299224854\n",
      "Epoch 167: curr_epoch_loss=0.192032128572464\n",
      "Epoch 168: curr_epoch_loss=0.19136804342269897\n",
      "Epoch 169: curr_epoch_loss=0.19114847481250763\n",
      "Epoch 170: curr_epoch_loss=0.19476227462291718\n",
      "Epoch 171: curr_epoch_loss=0.1906857043504715\n",
      "Epoch 172: curr_epoch_loss=0.19169723987579346\n",
      "Epoch 173: curr_epoch_loss=0.19300144910812378\n",
      "Epoch 174: curr_epoch_loss=0.19167494773864746\n",
      "Epoch 175: curr_epoch_loss=0.1911708116531372\n",
      "Epoch 176: curr_epoch_loss=0.19070759415626526\n",
      "Epoch 177: curr_epoch_loss=0.19301746785640717\n",
      "Epoch 178: curr_epoch_loss=0.19157715141773224\n",
      "Epoch 179: curr_epoch_loss=0.19206193089485168\n",
      "Epoch 180: curr_epoch_loss=0.19035115838050842\n",
      "Epoch 181: curr_epoch_loss=0.19049614667892456\n",
      "Epoch 182: curr_epoch_loss=0.19140395522117615\n",
      "Epoch 183: curr_epoch_loss=0.19112172722816467\n",
      "Epoch 184: curr_epoch_loss=0.1907990574836731\n",
      "Epoch 185: curr_epoch_loss=0.1914144605398178\n",
      "Epoch 186: curr_epoch_loss=0.1891907900571823\n",
      "Epoch 187: curr_epoch_loss=0.18900400400161743\n",
      "Epoch 188: curr_epoch_loss=0.1897030919790268\n",
      "Epoch 189: curr_epoch_loss=0.1902790069580078\n",
      "Epoch 190: curr_epoch_loss=0.18793970346450806\n",
      "Epoch 191: curr_epoch_loss=0.18931016325950623\n",
      "Epoch 192: curr_epoch_loss=0.18903620541095734\n",
      "Epoch 193: curr_epoch_loss=0.1879924237728119\n",
      "Epoch 194: curr_epoch_loss=0.1873900443315506\n",
      "Epoch 195: curr_epoch_loss=0.19095608592033386\n",
      "Epoch 196: curr_epoch_loss=0.18800821900367737\n",
      "Epoch 197: curr_epoch_loss=0.18901889026165009\n",
      "Epoch 198: curr_epoch_loss=0.18940265476703644\n",
      "Epoch 199: curr_epoch_loss=0.18943211436271667\n",
      "Epoch 200: curr_epoch_loss=0.18865904211997986\n",
      "Epoch 201: curr_epoch_loss=0.18693527579307556\n",
      "Epoch 202: curr_epoch_loss=0.18752264976501465\n",
      "Epoch 203: curr_epoch_loss=0.1876118779182434\n",
      "Epoch 204: curr_epoch_loss=0.18816974759101868\n",
      "Epoch 205: curr_epoch_loss=0.18725770711898804\n",
      "Epoch 206: curr_epoch_loss=0.1888023316860199\n",
      "Epoch 207: curr_epoch_loss=0.18808938562870026\n",
      "Epoch 208: curr_epoch_loss=0.18826588988304138\n",
      "Epoch 209: curr_epoch_loss=0.18833228945732117\n",
      "Epoch 210: curr_epoch_loss=0.18702709674835205\n",
      "Epoch 211: curr_epoch_loss=0.18800130486488342\n",
      "Epoch 212: curr_epoch_loss=0.18813654780387878\n",
      "Epoch 213: curr_epoch_loss=0.19113929569721222\n",
      "Epoch 214: curr_epoch_loss=0.18954771757125854\n",
      "Epoch 215: curr_epoch_loss=0.18683668971061707\n",
      "Epoch 216: curr_epoch_loss=0.1868065446615219\n",
      "Epoch 217: curr_epoch_loss=0.1881970912218094\n",
      "Epoch 218: curr_epoch_loss=0.18939557671546936\n",
      "Epoch 219: curr_epoch_loss=0.187056764960289\n",
      "Epoch 220: curr_epoch_loss=0.18887412548065186\n",
      "Epoch 221: curr_epoch_loss=0.18412141501903534\n",
      "Epoch 222: curr_epoch_loss=0.1854308843612671\n",
      "Epoch 223: curr_epoch_loss=0.18690980970859528\n",
      "Epoch 224: curr_epoch_loss=0.18548785150051117\n",
      "Epoch 225: curr_epoch_loss=0.18587729334831238\n",
      "Epoch 226: curr_epoch_loss=0.1867617666721344\n",
      "Epoch 227: curr_epoch_loss=0.18605977296829224\n",
      "Epoch 228: curr_epoch_loss=0.18452227115631104\n",
      "Epoch 229: curr_epoch_loss=0.1852962076663971\n",
      "Epoch 230: curr_epoch_loss=0.18587802350521088\n",
      "Epoch 231: curr_epoch_loss=0.18849775195121765\n",
      "Epoch 232: curr_epoch_loss=0.18344353139400482\n",
      "Epoch 233: curr_epoch_loss=0.18573802709579468\n",
      "Epoch 234: curr_epoch_loss=0.1850627213716507\n",
      "Epoch 235: curr_epoch_loss=0.18506309390068054\n",
      "Epoch 236: curr_epoch_loss=0.18237021565437317\n",
      "Epoch 237: curr_epoch_loss=0.1853460669517517\n",
      "Epoch 238: curr_epoch_loss=0.18550649285316467\n",
      "Epoch 239: curr_epoch_loss=0.1848733276128769\n",
      "Epoch 240: curr_epoch_loss=0.18331801891326904\n",
      "Epoch 241: curr_epoch_loss=0.18491089344024658\n",
      "Epoch 242: curr_epoch_loss=0.18478833138942719\n",
      "Epoch 243: curr_epoch_loss=0.18336434662342072\n",
      "Epoch 244: curr_epoch_loss=0.18419110774993896\n",
      "Epoch 245: curr_epoch_loss=0.18374332785606384\n",
      "Epoch 246: curr_epoch_loss=0.18267323076725006\n",
      "Epoch 247: curr_epoch_loss=0.18311506509780884\n",
      "Epoch 248: curr_epoch_loss=0.18244460225105286\n",
      "Epoch 249: curr_epoch_loss=0.18269187211990356\n",
      "Epoch 250: curr_epoch_loss=0.18252399563789368\n",
      "Epoch 251: curr_epoch_loss=0.183134526014328\n",
      "Epoch 252: curr_epoch_loss=0.18571828305721283\n",
      "Epoch 253: curr_epoch_loss=0.1825023591518402\n",
      "Epoch 254: curr_epoch_loss=0.1819649636745453\n",
      "Epoch 255: curr_epoch_loss=0.18350790441036224\n",
      "Epoch 256: curr_epoch_loss=0.18128497898578644\n",
      "Epoch 257: curr_epoch_loss=0.18751642107963562\n",
      "Epoch 258: curr_epoch_loss=0.18104569613933563\n",
      "Epoch 259: curr_epoch_loss=0.17986293137073517\n",
      "Epoch 260: curr_epoch_loss=0.18407978117465973\n",
      "Epoch 261: curr_epoch_loss=0.18128976225852966\n",
      "Epoch 262: curr_epoch_loss=0.18230164051055908\n",
      "Epoch 263: curr_epoch_loss=0.18091633915901184\n",
      "Epoch 264: curr_epoch_loss=0.18442749977111816\n",
      "Epoch 265: curr_epoch_loss=0.18027162551879883\n",
      "Epoch 266: curr_epoch_loss=0.1829642802476883\n",
      "Epoch 267: curr_epoch_loss=0.17943614721298218\n",
      "Epoch 268: curr_epoch_loss=0.17916147410869598\n",
      "Epoch 269: curr_epoch_loss=0.17926742136478424\n",
      "Epoch 270: curr_epoch_loss=0.1793433129787445\n",
      "Epoch 271: curr_epoch_loss=0.17670410871505737\n",
      "Epoch 272: curr_epoch_loss=0.1821022629737854\n",
      "Epoch 273: curr_epoch_loss=0.17919516563415527\n",
      "Epoch 274: curr_epoch_loss=0.18136942386627197\n",
      "Epoch 275: curr_epoch_loss=0.18069031834602356\n",
      "Epoch 276: curr_epoch_loss=0.1784214973449707\n",
      "Epoch 277: curr_epoch_loss=0.18058905005455017\n",
      "Epoch 278: curr_epoch_loss=0.1788061261177063\n",
      "Epoch 279: curr_epoch_loss=0.18048803508281708\n",
      "Epoch 280: curr_epoch_loss=0.1817910075187683\n",
      "Epoch 281: curr_epoch_loss=0.1795903444290161\n",
      "Epoch 282: curr_epoch_loss=0.1781153380870819\n",
      "Epoch 283: curr_epoch_loss=0.17978113889694214\n",
      "Epoch 284: curr_epoch_loss=0.17933152616024017\n",
      "Epoch 285: curr_epoch_loss=0.17953446507453918\n",
      "Epoch 286: curr_epoch_loss=0.18028490245342255\n",
      "Epoch 287: curr_epoch_loss=0.1799531877040863\n",
      "Epoch 288: curr_epoch_loss=0.17972680926322937\n",
      "Epoch 289: curr_epoch_loss=0.17886358499526978\n",
      "Epoch 290: curr_epoch_loss=0.18029248714447021\n",
      "Epoch 291: curr_epoch_loss=0.17979472875595093\n",
      "Epoch 292: curr_epoch_loss=0.17930293083190918\n",
      "Epoch 293: curr_epoch_loss=0.1773693859577179\n",
      "Epoch 294: curr_epoch_loss=0.17774534225463867\n",
      "Epoch 295: curr_epoch_loss=0.1788005232810974\n",
      "Epoch 296: curr_epoch_loss=0.1764553189277649\n",
      "Epoch 297: curr_epoch_loss=0.17821696400642395\n",
      "Epoch 298: curr_epoch_loss=0.1778862476348877\n",
      "Epoch 299: curr_epoch_loss=0.17454248666763306\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word2vec.wv)\n",
    "embedding_dim = 50\n",
    "num_filters = 64\n",
    "filter_size = 3\n",
    "hidden_dim = 50\n",
    "dropout = 0.5\n",
    "\n",
    "model2 = SentenceSimilarityCNN2(embedding_dim, num_filters, filter_size, hidden_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model2.parameters(), lr=1e-1)\n",
    "n_epochs=300\n",
    "def train2(train_loader, n_epochs=n_epochs):\n",
    "    model2.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        curr_epoch_loss = []\n",
    "        for x1, x2, y in train_loader:\n",
    "            #print(x1.shape)\n",
    "            y_hat = model2(x1, x2)\n",
    "            loss = criterion(y_hat, y.float())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            curr_epoch_loss.append(loss.cpu().data.numpy())\n",
    "\n",
    "        print(f\"Epoch {epoch}: curr_epoch_loss={np.mean(curr_epoch_loss)}\")\n",
    "\n",
    "    return model2\n",
    "\n",
    "model2 = train2(train_dataloader)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8848, 0.8135, 0.8243, 0.3027, 0.3985, 0.6128, 0.1648, 0.8003, 0.2580,\n",
      "        0.7016, 0.1642, 0.5528, 0.1018, 0.7509, 0.8117, 0.6865, 0.3902, 0.6230,\n",
      "        0.5437, 0.7694, 0.8488, 0.9468, 0.7618, 0.6670, 0.7348, 0.3410, 0.9430,\n",
      "        0.7598, 0.6055, 0.0751, 0.5706, 0.4782, 0.7741, 0.4403, 0.7017, 0.4447,\n",
      "        0.2465, 0.7648, 1.0000, 0.9194, 0.8605, 0.5588, 0.6628, 0.5393, 0.3770,\n",
      "        0.7314, 0.7099, 0.8232, 0.9117, 0.8451, 0.7416, 0.6973, 0.8317, 0.5462,\n",
      "        0.3315, 0.6967, 0.9092, 0.6745, 0.7961, 0.6803, 0.7772, 0.5524, 0.7786,\n",
      "        0.6491], grad_fn=<ExpBackward0>)\n",
      "tensor([1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "tensor([1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
      "        0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "def eval_model2(model, test_dataloader):\n",
    "    model.eval()\n",
    "    for x1, x2, y in test_dataloader:\n",
    "        y_hat = model(x1, x2)\n",
    "        print(y_hat)\n",
    "        y_pred = torch.zeros(y_hat.shape)\n",
    "        y_pred = (y_hat > 0.5).int()\n",
    "        print(y_pred)\n",
    "        print(y)\n",
    "        break\n",
    "\n",
    "eval_model2(model2, train_dataloader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " bn_Testing Similarity Scoring Function_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [],
   "source": [
    "NUM_OF_SAMPLES = 20\n",
    "SAMPLE_SIZE = 2\n",
    "OUTPUT_SIZE = 6\n",
    "\n",
    "test_embedding = torch.rand((NUM_OF_SAMPLES, SAMPLE_SIZE, OUTPUT_SIZE))\n",
    "scores = manhattan_similarity_score(test_embedding)\n",
    "\n",
    "assert scores.shape == (NUM_OF_SAMPLES, 1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T00:35:09.386951Z",
     "end_time": "2023-04-08T00:35:09.528280Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [],
   "source": [
    "class SSCN(nn.Module):\n",
    "    def __init__(self, sample_size, stride=1, kernel_size=3, padding=1):\n",
    "        super().__init__()\n",
    "        self.stride = stride\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        self.conv_layers =sample_size\n",
    "\n",
    "        #NN layers\n",
    "        self.conv1 = nn.Conv1d(in_channels=self.conv_layers, out_channels=self.conv_layers, \\\n",
    "                               kernel_size=self.kernel_size, padding=self.padding)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(in_channels=self.conv_layers, out_channels=self.conv_layers, \\\n",
    "                               kernel_size=self.kernel_size, padding=self.padding)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool1 = DynamicKMaxPooling(self.kernel_size, self.conv_layers)\n",
    "\n",
    "        self.sscn = nn.Sequential(self.conv1, self.relu1, self.conv2, self.relu2, self.pool1)\n",
    "\n",
    "    \"\"\"\n",
    "    * X: Pooled output of SSCN model of shape (sample_size, -1)\n",
    "    * For the purpose of this experiment sample_size = 2\n",
    "    \"\"\"\n",
    "    def manhattan_similarity_score(self, X):\n",
    "        score = manhattan_similarity_score(X)\n",
    "        return score\n",
    "\n",
    "    def forward(self, X):\n",
    "        # X = self.conv1(X)\n",
    "        # print(X.shape)\n",
    "        # X = self.relu1(X)\n",
    "        # print(X.shape)\n",
    "        # X = self.conv1(X)\n",
    "        # print(X.shape)\n",
    "        # X = self.relu2(X)\n",
    "        # print(X.shape)\n",
    "        # X = self.pool1(X)\n",
    "        # print(X.shape)\n",
    "        # X = self.manhattan_similarity_score(X)\n",
    "        # print(X.shape)\n",
    "        X = self.manhattan_similarity_score(self.sscn(X))\n",
    "        return X"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T00:35:09.387486Z",
     "end_time": "2023-04-08T00:35:09.528347Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "__Testing:__"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSCN(\n",
      "  (conv1): Conv1d(2, 2, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (relu1): ReLU()\n",
      "  (conv2): Conv1d(2, 2, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (relu2): ReLU()\n",
      "  (pool1): DynamicKMaxPooling()\n",
      "  (sscn): Sequential(\n",
      "    (0): Conv1d(2, 2, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): ReLU()\n",
      "    (2): Conv1d(2, 2, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (3): ReLU()\n",
      "    (4): DynamicKMaxPooling()\n",
      "  )\n",
      ")\n",
      "torch.Size([20, 1])\n"
     ]
    }
   ],
   "source": [
    "NUM_OF_SAMPLES = 20\n",
    "SAMPLE_SIZE = 2\n",
    "UNIQUE_FEATURES = 18\n",
    "\n",
    "test_embedding = torch.rand((NUM_OF_SAMPLES, SAMPLE_SIZE, UNIQUE_FEATURES))\n",
    "\n",
    "model = SSCN(SAMPLE_SIZE)\n",
    "# shape (batch,sample,sentence,word)?\n",
    "print(model)\n",
    "\n",
    "out = model(test_embedding)\n",
    "\n",
    "assert out.shape[0] == NUM_OF_SAMPLES\n",
    "assert out.shape[1] == 1\n",
    "print(out.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T00:35:09.388774Z",
     "end_time": "2023-04-08T00:35:09.528518Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
