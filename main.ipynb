{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import datetime\n",
    "import torch, stanza\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import gensim\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T10:03:10.066076Z",
     "end_time": "2023-04-03T10:03:10.093062Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Processing\n",
    "\n",
    "This section can have stuff related to data prep.\n",
    "\n",
    "\n",
    "Should the MSPC Dataset be a part of this section? - Adam"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def read_file(file_name):\n",
    "    # Note: Unable to use pd.read_csv... the function complained about an issue with the formatting of the tsv file\n",
    "    # train = pd.read_csv('data/msr_paraphrase_train.txt', sep='\\t', encoding='latin1')\n",
    "    # train\n",
    "\n",
    "    # opting to read file in and split columns manually to create a pandas dataframe\n",
    "    list = []\n",
    "    with open(file_name, encoding=\"utf8\") as f:\n",
    "        lines = f.readlines()\n",
    "        for i, line in enumerate(lines):\n",
    "            fields = line.split('\\t')\n",
    "            list.append(fields)\n",
    "\n",
    "    df = pd.DataFrame(list[1:], columns=['Quality', 'ID1', 'ID2', 'String1', 'String2'])\n",
    "    return df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T10:03:11.846425Z",
     "end_time": "2023-04-03T10:03:11.961473Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Definition\n",
    "\n",
    "![Model Overview](./images/overview.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Input Layer\n",
    "\n",
    "In the input layer is made up of a Stanford Parser to provide a syntactic tree so that the model can extract significant words (mainly, subject, predicate, object) in the input corpus. Word2Vec is then used to map the words into vectors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 12:20:32 INFO: Loading these models for language: en (English):\n",
      "===========================\n",
      "| Processor    | Package  |\n",
      "---------------------------\n",
      "| tokenize     | combined |\n",
      "| pos          | combined |\n",
      "| constituency | wsj      |\n",
      "===========================\n",
      "\n",
      "2023-04-04 12:20:32 INFO: Using device: cpu\n",
      "2023-04-04 12:20:32 INFO: Loading: tokenize\n",
      "2023-04-04 12:20:32 INFO: Loading: pos\n",
      "2023-04-04 12:20:32 INFO: Loading: constituency\n",
      "2023-04-04 12:20:33 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "# set 'download_method = None' to not download the resources over and over\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,pos,constituency', download_method=None)\n",
    "\n",
    "def trunk_construction(str, parent_label = None):\n",
    "    doc = nlp(str)\n",
    "    tree = doc.sentences[0].constituency\n",
    "\n",
    "    words = construct_sentence(tree, parent_label)\n",
    "    return ' '.join(words)\n",
    "\n",
    "def construct_sentence(tree, parent_label = None, leave_pos=False):\n",
    "\n",
    "    sentences = []\n",
    "    if 'NN' in tree.label:\n",
    "        if parent_label == 'NP':\n",
    "            # sentences.append(tree)\n",
    "            sentences = sentences + tree.leaf_labels()\n",
    "    if 'VB' in tree.label:\n",
    "        if parent_label == 'VP':\n",
    "            #sentences.append(tree)\n",
    "            sentences = sentences + tree.leaf_labels()\n",
    "    for child in tree.children:\n",
    "        sentences = sentences + construct_sentence(child, tree.label)\n",
    "\n",
    "    return sentences"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T10:04:18.060872Z",
     "end_time": "2023-04-03T10:04:19.534303Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def test_parser(str, valid_sentence):\n",
    "\n",
    "    new_sentence = trunk_construction(str)\n",
    "    #new_sentence = ' '.join(words)\n",
    "    assert new_sentence == valid_sentence"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T10:04:21.340321Z",
     "end_time": "2023-04-03T10:04:21.361946Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Parser Test Cases\n",
    "Test the parser using some of the training data sentences as input and asserting the output sentence matches the algorithm defined in the paper."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "test_parser('Syrian forces launch new attacks', \"forces launch attacks\")\n",
    "test_parser(\"\"\"the flat tire was replaced by the driver\"\"\",\"tire was replaced driver\")\n",
    "test_parser(\"\"\"Amrozi accused his brother, whom he called \"the witness\", of deliberately distorting his evidence.\"\"\",\n",
    "           \"Amrozi accused brother called witness distorting evidence\")\n",
    "test_parser(\"\"\"Shares of Genentech, a much larger company with several products on the market, rose more than 2 percent\"\"\",\n",
    "            \"Shares Genentech company products market rose percent\")\n",
    "test_parser(\"\"\"Gyorgy Heizler, head of the local disaster unit, said the coach was carrying 38 passengers.\"\"\",\n",
    "             \"Gyorgy Heizler head disaster unit said coach was carrying passengers\")\n",
    "test_parser(\"\"\"Referring to him as only \"the witness\", Amrozi accused his brother of deliberately distorting his evidence.\"\"\",\n",
    "           \"Referring witness Amrozi accused brother distorting evidence\")\n",
    "test_parser(\"\"\"His wife said he was \"100 percent behind George Bush\" and looked forward to using his years of training in the war.\"\"\",\n",
    "            \"wife said was percent George Bush looked using years training war\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T13:34:07.203441Z",
     "end_time": "2023-04-03T13:34:14.836359Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sentence Preprocessing\n",
    "pass the input sentences from the training dataset through the stanford/stanza parser, extracting the relevant parts of speech and then tokenize the processed sentences using the gensim.utils.simple_preprocess utility"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# start_time = datetime.datetime.now()\n",
    "#\n",
    "# processed_string1 = df[:500].String1.apply(trunk_construction)\n",
    "# processed_string2 = df[:500].String2.apply(trunk_construction)\n",
    "#\n",
    "# end_time = datetime.datetime.now()\n",
    "#\n",
    "# print (f\"Processing 200 sentences with stanza library took {end_time - start_time}\")\n",
    "#\n",
    "# start_time = datetime.datetime.now()\n",
    "#\n",
    "# processed_string1 = processed_string1.apply(gensim.utils.simple_preprocess)\n",
    "# processed_string2 = processed_string2.apply(gensim.utils.simple_preprocess)\n",
    "#\n",
    "# end_time = datetime.datetime.now()\n",
    "#\n",
    "# print (f\"Processing 200 sentences with gensim.utils.simple_preprocess took {end_time - start_time}\")\n",
    "# print(f\"Number of sentences processed in the String1 column: len(processed_string1\")\n",
    "# print(f\"Number of sentences processed in the String2 column: len(processed_string2\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Word2Vec Embeddings\n",
    "Take the preprocessed and tokenized sentences and use Word2Vec to get the word embeddings.  Take each word embedding in a sentence and find the mean which will represent the embedding for the sentence."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# from gensim.models import Word2Vec\n",
    "#\n",
    "# corpus = pd.concat([processed_string1, processed_string2], ignore_index=True)\n",
    "#\n",
    "# #model = Word2Vec(sentences=corpus, vector_size=(len(processed_string1) + len(processed_string2)), min_count=2)\n",
    "# # set vector size to reduce computational complexity\n",
    "# model = Word2Vec(sentences=corpus, min_count=1, window=2, vector_size=50)\n",
    "# #model.build_vocab(sentences=corpus)\n",
    "# #model.train(corpus, total_examples=model.corpus_count, epochs=5)\n",
    "#\n",
    "# print(model)\n",
    "# print(model.wv.key_to_index)\n",
    "#\n",
    "# model.wv.get_vector('president')\n",
    "#\n",
    "# # for index, word in enumerate(model.wv.index_to_key):\n",
    "# #     if index == 120:\n",
    "# #         break\n",
    "# #     print(f\"word #{index}/{len(model.wv.index_to_key)} is {word}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Function is broken out for testing purposes\n",
    "def generate_word2vec_model(corpus):\n",
    "    # Creating the Word2Vec model\n",
    "    model = Word2Vec(sentences=corpus, min_count=1, window=2, vector_size=50)\n",
    "\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# Function is broken out for testing purposes\n",
    "def sentence_embeddings(w2v_model, sentence):\n",
    "    list = []\n",
    "    for word in sentence:\n",
    "        list.append(w2v_model.wv.get_vector(word))\n",
    "\n",
    "    word_matrix = np.row_stack(list)\n",
    "    return np.mean(word_matrix, axis=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "def test_word2vec():\n",
    "\n",
    "    df = read_file('data/msr_paraphrase_train.txt')\n",
    "\n",
    "    sentences1 = df.String1[:5].apply(gensim.utils.simple_preprocess)\n",
    "    sentences2 = df.String2[:5].apply(gensim.utils.simple_preprocess)\n",
    "\n",
    "    corpus = pd.concat([sentences1, sentences2], ignore_index=True)\n",
    "\n",
    "    model = generate_word2vec_model(corpus)\n",
    "\n",
    "    # Not sure if this will always generate the same embedding\n",
    "    test_embedding = np.array([-0.00113049, -0.00124808,  0.00252251,  0.00058141,  0.00187964,  0.00379025,\n",
    "              -0.00012356,  0.00347055, -0.00241507,  0.00545258, -0.00574078, -0.00489824,\n",
    "              -0.00224492,  0.00744946,  0.00350835, -0.00139295, -0.00081134,  0.00655962,\n",
    "              0.00244374, -0.00447209, -0.00124291, -0.00092616,  0.0021044,  -0.00092541,\n",
    "              0.00284307,  0.00367638,  0.00364716,  0.00519976, -0.00088121,  0.00109841,\n",
    "              -0.00219322, -0.00372483,  0.00078702, -0.00612309, -0.00312131,  0.00088071,\n",
    "              0.00503909, -0.0009484,  -0.00068209, -0.0004782,   0.00367015,  0.00314679,\n",
    "              -0.00302592,  0.00346377,  0.00151145, -0.00076442, -0.0012528,  -0.00087095,\n",
    "              -0.00075365,  0.00468711])\n",
    "\n",
    "    embedding = sentence_embeddings(model, corpus[0])\n",
    "\n",
    "    assert embedding.shape == (50,)\n",
    "\n",
    "    # not sure if this will always be equal based on comment on test_embedding variable\n",
    "    assert np.allclose(embedding, test_embedding)\n",
    "\n",
    "test_word2vec()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "def corpus_embeddings(model, corpus):\n",
    "    embeddings_list = []\n",
    "    for sentence in corpus:\n",
    "        embeddings_list.append(sentence_embeddings(model, sentence))\n",
    "\n",
    "    return np.row_stack(embeddings_list)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Dataset for the MSPC dataset\n",
    "class MSPCDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        tsv_file (string): path to the tsv file with sentences to compare and associate quality score\n",
    "        num_records (int): number of records to load.  Defaults to None which is all\n",
    "    \"\"\"\n",
    "    def __init__(self, tsv_file, num_records=None):\n",
    "        df = read_file('data/msr_paraphrase_train.txt')\n",
    "\n",
    "        start_time = datetime.datetime.now()\n",
    "\n",
    "        if num_records is not None:\n",
    "            processed_string1 = df[:num_records].String1.apply(trunk_construction)\n",
    "            processed_string2 = df[:num_records].String2.apply(trunk_construction)\n",
    "            self.quality = df[:num_records].Quality\n",
    "        else:\n",
    "            processed_string1 = df.String1.apply(trunk_construction)\n",
    "            processed_string2 = df.String2.apply(trunk_construction)\n",
    "            self.quality = df.Quality\n",
    "\n",
    "        end_time = datetime.datetime.now()\n",
    "\n",
    "        print (f\"Processing 200 sentences with stanza library took {end_time - start_time}\")\n",
    "\n",
    "        start_time = datetime.datetime.now()\n",
    "\n",
    "        processed_string1 = processed_string1.apply(gensim.utils.simple_preprocess)\n",
    "        processed_string2 = processed_string2.apply(gensim.utils.simple_preprocess)\n",
    "\n",
    "        end_time = datetime.datetime.now()\n",
    "\n",
    "        corpus = pd.concat([processed_string1, processed_string2], ignore_index=True)\n",
    "\n",
    "        w2v_model = generate_word2vec_model(corpus)\n",
    "\n",
    "        sentence_embeddings1 = corpus_embeddings(w2v_model, processed_string1)\n",
    "        sentence_embeddings2 = corpus_embeddings(w2v_model, processed_string2)\n",
    "\n",
    "\n",
    "\n",
    "        self.sentences_embeddings1 = sentence_embeddings1\n",
    "        self.sentences_embeddings2 = sentence_embeddings2\n",
    "\n",
    "        print (f\"Processing 200 sentences with gensim.utils.simple_preprocess took {end_time - start_time}\")\n",
    "        print(f\"Number of sentences processed in the String1 column: {len(processed_string1)}\")\n",
    "        print(f\"Number of sentences processed in the String2 column: {len(processed_string2)}\")\n",
    "        #print(self.sentences_embeddings1)\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences_embeddings1)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.sentences_embeddings1[i], self.sentences_embeddings2[i], self.quality[i]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T10:06:47.128634Z",
     "end_time": "2023-04-03T10:06:48.232988Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 200 sentences with stanza library took 0:00:06.489651\n",
      "Processing 200 sentences with gensim.utils.simple_preprocess took 0:00:00.000997\n",
      "Number of sentences processed in the String1 column: 10\n",
      "Number of sentences processed in the String2 column: 10\n",
      "(array([-0.00198056,  0.00452067, -0.00300886, -0.00332817,  0.0005654 ,\n",
      "       -0.00571383, -0.00130734,  0.00222749, -0.00271983,  0.00259559,\n",
      "       -0.00042913, -0.00666595, -0.00520164,  0.00599408,  0.00242181,\n",
      "        0.00821459,  0.00473668, -0.0004835 ,  0.00094157, -0.00775254,\n",
      "        0.00124578,  0.00033029, -0.00147425,  0.00130682,  0.00093901,\n",
      "        0.00575981, -0.00139975,  0.00036692,  0.00320067, -0.00132761,\n",
      "       -0.00065307, -0.00116841,  0.00637745, -0.00275588,  0.00029436,\n",
      "        0.0025276 ,  0.00983984,  0.00815548, -0.00666484, -0.0018606 ,\n",
      "        0.00654633, -0.00289515,  0.00369345,  0.00664935,  0.00236211,\n",
      "       -0.00282075, -0.00704209, -0.0010638 , -0.00042502,  0.00569323],\n",
      "      dtype=float32), array([ 1.3117758e-04,  8.0318134e-03, -3.4688062e-03, -5.5877748e-03,\n",
      "        2.9175777e-03, -3.7761044e-03,  3.3677716e-04,  4.6032900e-03,\n",
      "       -1.3689653e-03,  9.8244112e-04, -4.4690361e-03, -3.7602973e-03,\n",
      "       -6.8011270e-03,  2.4121914e-03, -1.6859559e-03,  8.3722947e-03,\n",
      "        1.3138120e-03,  5.2171893e-04,  2.7495434e-03, -6.2463069e-03,\n",
      "        2.4489036e-03,  2.0122181e-03,  1.9221026e-03,  2.5584612e-03,\n",
      "       -4.5463044e-04,  7.3493323e-03,  2.6105109e-03, -3.6812131e-03,\n",
      "        7.8176096e-04, -8.3839626e-04, -5.2651092e-03, -3.2025459e-03,\n",
      "        4.0372508e-03, -1.4093017e-03,  5.3046033e-04,  9.1533046e-05,\n",
      "        8.1477547e-03,  5.0110859e-03, -3.6015864e-03, -7.0368740e-05,\n",
      "        8.0861766e-03, -1.4953479e-03,  2.7228545e-03,  7.8077028e-03,\n",
      "        1.0483289e-03, -3.3851448e-04, -3.7115160e-03, -1.2319729e-03,\n",
      "        1.7521650e-04,  1.4382934e-03], dtype=float32), '1')\n"
     ]
    }
   ],
   "source": [
    "def test_dataset():\n",
    "    dataset = MSPCDataset('data/msr_paraphrase_train.txt', 10)\n",
    "    assert len(dataset) == 10\n",
    "    # print(dataset[0])\n",
    "test_dataset()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T10:06:48.132749Z",
     "end_time": "2023-04-03T10:06:49.269964Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Input Layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "class inputLayer(nn.Module):\n",
    "    def __init__(self, nlp_pipeline):\n",
    "        super().__init__()\n",
    "        self.nlp = nlp_pipeline\n",
    "\n",
    "    def construct_sentence(self, tree, parent_label = None, leave_pos=False):\n",
    "        sentences = []\n",
    "        if 'NN' in tree.label:\n",
    "            if parent_label == 'NP':\n",
    "                # sentences.append(tree)\n",
    "                sentences = sentences + tree.leaf_labels()\n",
    "        if 'VB' in tree.label:\n",
    "            if parent_label == 'VP':\n",
    "                #sentences.append(tree)\n",
    "                sentences = sentences + tree.leaf_labels()\n",
    "        for child in tree.children:\n",
    "            sentences = sentences + construct_sentence(child, tree.label)\n",
    "        return sentences\n",
    "\n",
    "    \"\"\"\n",
    "    Here we take the output of the Stanford Parser and pass it to\n",
    "    Word2Vec in order to create a vector.\n",
    "    \"\"\"\n",
    "    def embed_vector(self, words):\n",
    "        pass\n",
    "\n",
    "    def forward(self, input_sentence, parent_label = None):\n",
    "        doc = self.nlp(input_sentence)\n",
    "        tree = doc.sentences[0].constituency\n",
    "        words = construct_sentence(tree, parent_label)\n",
    "        out = ' '.join(words)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T13:51:30.656382Z",
     "end_time": "2023-04-03T13:51:30.746508Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "__Testing:__"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 13:51:34 INFO: Loading these models for language: en (English):\n",
      "===========================\n",
      "| Processor    | Package  |\n",
      "---------------------------\n",
      "| tokenize     | combined |\n",
      "| pos          | combined |\n",
      "| constituency | wsj      |\n",
      "===========================\n",
      "\n",
      "2023-04-03 13:51:34 INFO: Using device: cpu\n",
      "2023-04-03 13:51:34 INFO: Loading: tokenize\n",
      "2023-04-03 13:51:34 INFO: Loading: pos\n",
      "2023-04-03 13:51:35 INFO: Loading: constituency\n",
      "2023-04-03 13:51:36 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,pos,constituency', download_method=None)\n",
    "\n",
    "def test_input_layer(str, valid_sentence):\n",
    "\n",
    "    in_layer = inputLayer(nlp)\n",
    "    new_sentence = in_layer(str)\n",
    "    #new_sentence = ' '.join(words)\n",
    "    assert new_sentence == valid_sentence\n",
    "\n",
    "test_parser('Syrian forces launch new attacks', \"forces launch attacks\")\n",
    "test_parser(\"\"\"the flat tire was replaced by the driver\"\"\",\"tire was replaced driver\")\n",
    "test_parser(\"\"\"Amrozi accused his brother, whom he called \"the witness\", of deliberately distorting his evidence.\"\"\",\n",
    "           \"Amrozi accused brother called witness distorting evidence\")\n",
    "test_parser(\"\"\"Shares of Genentech, a much larger company with several products on the market, rose more than 2 percent\"\"\",\n",
    "            \"Shares Genentech company products market rose percent\")\n",
    "test_parser(\"\"\"Gyorgy Heizler, head of the local disaster unit, said the coach was carrying 38 passengers.\"\"\",\n",
    "             \"Gyorgy Heizler head disaster unit said coach was carrying passengers\")\n",
    "test_parser(\"\"\"Referring to him as only \"the witness\", Amrozi accused his brother of deliberately distorting his evidence.\"\"\",\n",
    "           \"Referring witness Amrozi accused brother distorting evidence\")\n",
    "test_parser(\"\"\"His wife said he was \"100 percent behind George Bush\" and looked forward to using his years of training in the war.\"\"\",\n",
    "            \"wife said was percent George Bush looked using years training war\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T13:51:34.819791Z",
     "end_time": "2023-04-03T13:51:42.329930Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pooling Layers\n",
    "\n",
    "The original paper used a dynamic k-max pooling method in their model. The _k_ value is determine by equation (1).\n",
    "\n",
    "\\begin{equation*} k=\\max \\left({k_{top},\\left \\lceil{ \\frac {L-l}{L} \\left |{ s }\\right | }\\right \\rceil }\\right)\\end{equation*}\n",
    "\n",
    "__Dynamic K-Max Pooling Implementation:__"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "#https://gist.github.com/anna-hope/7a2b2e66c3645aa8e4f94dbf06aed8dc\n",
    "\n",
    "class DynamicKMaxPool(nn.Module):\n",
    "    def __init__(self, k_top, L):\n",
    "        super().__init__()\n",
    "        # \"L is the total  number  of  convolutional  layers\n",
    "        # in  the  network;\n",
    "        # ktop is the fixed pooling parameter for the\n",
    "        # topmost  convolutional  layer\"\n",
    "        self.k_top = k_top\n",
    "        self.L = L\n",
    "\n",
    "    def forward(self, X, l):\n",
    "        s = X.size(dim=2)\n",
    "        dyn_k = ((self.L - l) / self.L) * s\n",
    "        k_max = max(self.k_top, np.ceil(dyn_k))\n",
    "        print(self.k_top, np.ceil(dyn_k))\n",
    "        out = F.adaptive_avg_pool1d(X, k_max)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T13:52:12.884684Z",
     "end_time": "2023-04-03T13:52:12.919840Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "__Testing:__"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.4922, 0.1095, 0.7784],\n",
      "         [0.6618, 0.8248, 0.3079],\n",
      "         [0.7897, 0.6921, 0.0027]],\n",
      "\n",
      "        [[0.2509, 0.6090, 0.0118],\n",
      "         [0.8836, 0.5662, 0.1784],\n",
      "         [0.7990, 0.5158, 0.5854]],\n",
      "\n",
      "        [[0.4951, 0.0020, 0.5179],\n",
      "         [0.4915, 0.8771, 0.0695],\n",
      "         [0.7113, 0.9584, 0.1733]]])\n",
      "3 0.0\n",
      "tensor([[[0.4922, 0.1095, 0.7784],\n",
      "         [0.6618, 0.8248, 0.3079],\n",
      "         [0.7897, 0.6921, 0.0027]],\n",
      "\n",
      "        [[0.2509, 0.6090, 0.0118],\n",
      "         [0.8836, 0.5662, 0.1784],\n",
      "         [0.7990, 0.5158, 0.5854]],\n",
      "\n",
      "        [[0.4951, 0.0020, 0.5179],\n",
      "         [0.4915, 0.8771, 0.0695],\n",
      "         [0.7113, 0.9584, 0.1733]]])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand((3,3,3))\n",
    "print(X)\n",
    "dynMaxPool = DynamicKMaxPool(3,1)\n",
    "print(dynMaxPool(X,1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T13:52:15.946133Z",
     "end_time": "2023-04-03T13:52:15.996850Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sentence Similarity\n",
    "\n",
    " \\begin{align*} Man(\\vec V_{x}, \\vec V_{y})=&\\left |{ x_{1}-y_{1} }\\right |\\! +\\! \\left |{ x_{2}-y_{2} }\\right | \\!+ \\!\\ldots \\!+ \\!\\left |{ x_{n}-y_{n} }\\right |\n",
    " \\\\ score=&e^{-Man(\\vec V_{x}, \\vec V_{y})},\\quad score\\in [{0,1}] \\end{align*}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
